<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小黄的记录`Blog</title>
  
  <subtitle>天道酬勤</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-01-29T09:16:24.233Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>小黄</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka |【2】核心原理</title>
    <link href="http://example.com/posts/acfeb110.html"/>
    <id>http://example.com/posts/acfeb110.html</id>
    <published>2024-01-28T08:21:41.359Z</published>
    <updated>2024-01-29T09:16:24.233Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Kafka生产者幂等性原理"><a href="#1-Kafka生产者幂等性原理" class="headerlink" title="1. Kafka生产者幂等性原理"></a>1. Kafka生产者幂等性原理</h1><p>Kafka的Producer发送消息时，Broker会返回ACK，Producer收到ACK才确认发送成功，否则会进行Retry，相当于Producer发送了两次一样的消息内容，此时可能有幂等性的问题 — <strong>导致生产者发送消息重复的问题</strong>。</p><p><img src="/Kafka%E3%80%902%E3%80%91%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86.assets%5Cimage-20240129120725088.png" alt="image-20240129120725088"></p><p>为了实现生产者的幂等性，Kafka引入了 Producer ID（PID）和 Sequence Number的概念。</p><ul><li><p>如果开启了这一项props.put(“enable.idempot”,true);，则Producer除了会发送消息，还会携带上PID和Seq</p></li><li><p>PID：每个Producer在初始化时，都会分配一个唯一的PID。</p></li><li><p>Sequence Number：针对每个PID，发送到指定主题指定分区的消息都对应一个从0开始递增的Sequence Number</p></li></ul><p><img src="/Kafka%E3%80%902%E3%80%91%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86.assets%5Cimage-20240129120550120.png" alt="image-20240129120550120"></p><ul><li>通过这两个量，Broker去对同一个分区的同一个PID进行seq的大小判断，根据 《5》判断决定是否保存消息，保证幂等性。</li></ul><h1 id="2-生产者分区写入策略"><a href="#2-生产者分区写入策略" class="headerlink" title="2. 生产者分区写入策略"></a>2. 生产者分区写入策略</h1><p>生产者将消息发送到Topic (的Partition)，其实是Kafka依据不同的策略将数据分配到不同的分区中 (需要注意不同的分区是分配在不同的Broker上的)。</p><ul><li>轮询分区策略</li><li>随机分区策略</li><li>按key分区策略</li><li>自定义分区策略</li></ul><h3 id="轮询分区策略"><a href="#轮询分区策略" class="headerlink" title="轮询分区策略"></a>轮询分区策略</h3><img src="Kafka【2】核心原理.assets\image-20240129122432254.png" alt="image-20240129122432254" style="zoom:80%;" /><ul><li>默认的策略，也是使用的最多的策略，可以最大限度的保证所有消息平均分配到每一个分区</li><li>如果在生产消息的时候，key为null，则默认使用轮询算法。否则不会使用轮询。</li></ul><h3 id="随机分区策略"><a href="#随机分区策略" class="headerlink" title="随机分区策略"></a>随机分区策略</h3><p>随机把消息分配到Topic的分区，基本不用。</p><h3 id="按Key分区策略"><a href="#按Key分区策略" class="headerlink" title="按Key分区策略"></a>按Key分区策略</h3><img src="Kafka【2】核心原理.assets\image-20240129140918531.png" alt="image-20240129140918531" style="zoom:80%;" /><ul><li>key .hashcode  %  分区数量</li><li>如果消息有key值，那么会使用这个策略</li><li>可能会出现【数据倾斜】，例如某个Key包含了大量的数据，因为Key值一样，因此所有的数据都会分配到同一个分区，造成该分区的消息数量远大于其他分区。</li></ul><h4 id="消息有序性的问题"><a href="#消息有序性的问题" class="headerlink" title="消息有序性的问题"></a>消息有序性的问题</h4><p>使用轮询分区或随机分区，会导致一段连续的数据被打散存储到不同的Partition，导致消费的无序性。</p><p>Kafka的消息是全局乱序，局部Partition是有序的。</p><p>但是使用按Key分区策略，可以把一段连续的数据存储到同一个Partition，这样做到这一段数据的有序。但可能会造成数据倾斜。</p><p><img src="/Kafka%E3%80%902%E3%80%91%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86.assets%5Cimage-20240129143618068.png" alt="image-20240129143618068"></p><h3 id="自定义分区策略"><a href="#自定义分区策略" class="headerlink" title="自定义分区策略"></a>自定义分区策略</h3><p>自定义分区组件</p><p>在Kafka生产者配置中，指定使用自定义分区器的类名</p><h1 id="3-消费者组-Rebalance机制"><a href="#3-消费者组-Rebalance机制" class="headerlink" title="3. 消费者组 Rebalance机制"></a>3. 消费者组 Rebalance机制</h1><p>Kafka中的Rebalance称之为再均衡，是Kafka中确保消费者组下所有消费者如何达成一致，分配（订阅的Topic的）分区的机制</p><p><strong>Rebalance触发的时机有</strong>：</p><ul><li>消费者组中消费者的个数发送变化。例如有新的消费者加入消费者组，或者某个消费者停止了。</li><li>消费者组内订阅的Topic个数发生变化<ul><li>消费者可以订阅多个主题</li><li>假设当前的消费者组的三个消费者总共订阅了三个Topic，但有一个Topic突然被删除了，此时也需要发生再均衡。</li></ul></li></ul><img src="C:\Users\26411\Desktop\blog\source\_posts\学习分享\Kafka【2】核心原理.assets\image-20240129161506526.png" alt="image-20240129161506526" style="zoom: 67%;" /><ul><li>订阅的Topic的Partition个数发生变化，Partition的个数增加或减少</li></ul><img src="C:\Users\26411\Desktop\blog\source\_posts\学习分享\Kafka【2】核心原理.assets\image-20240129162130804.png" alt="image-20240129162130804" style="zoom:67%;" /><h2 id="Rebalance的不良影响"><a href="#Rebalance的不良影响" class="headerlink" title="Rebalance的不良影响"></a>Rebalance的不良影响</h2><ul><li>发生Rebalance的时候，消费者组下的所有消费者都会协调在一起共同参与，Kafka使用分配策略，尽可能达到最公平的分配。</li><li>Rebalance的过程会对消费者组产生非常严重的影响，Rebalance的过程中所有的消费者都将停止工作，直到Rebalance完成。</li></ul><h1 id="4-消费者分区分配策略"><a href="#4-消费者分区分配策略" class="headerlink" title="4. 消费者分区分配策略"></a>4. 消费者分区分配策略</h1><h2 id="Range范围分配策略"><a href="#Range范围分配策略" class="headerlink" title="Range范围分配策略"></a>Range范围分配策略</h2><p>需要注意这个分配策略是针对 某一个Topic的。</p><p>例如消费者组订阅了两个Topic，那么针对这两个Topic，消费者组需要<strong>单独分别独立</strong>地走一下分配策略。</p><p>使用算法公式来决定每个消费者消费的分区范围</p><ul><li><p>n &#x3D; 分区数量 &#x2F; 消费者数量</p></li><li><p>m &#x3D; 分区数量 % 消费者数量</p></li><li><p>决策： 前m个消费者分别都消费n+1个分区；剩余消费者都消费n个分区</p></li></ul><p>两个例子</p><p><img src="C:\Users\26411\Desktop\blog\source_posts\学习分享\Kafka【2】核心原理.assets\image-20240129170723422.png" alt="image-20240129170723422"></p><p><img src="C:\Users\26411\Desktop\blog\source_posts\学习分享\Kafka【2】核心原理.assets\image-20240129171026153.png" alt="image-20240129171026153"></p><h2 id="RoundRobin轮询策略"><a href="#RoundRobin轮询策略" class="headerlink" title="RoundRobin轮询策略"></a>RoundRobin轮询策略</h2><p>轮询策略是将消费者组内所有消费者以及消费者所订阅的所有Topic的Partition按照字典序排序（Topic和Partition的hashcode排序）</p><p>然后通过轮询的方式逐个将分区分配给每个消费者。</p><p><img src="C:\Users\26411\Desktop\blog\source_posts\学习分享\Kafka【2】核心原理.assets\image-20240129171502153.png" alt="image-20240129171502153"></p><ol start="2"><li>分区和副本机制</li></ol><h2 id="生产消息"><a href="#生产消息" class="headerlink" title="生产消息"></a>生产消息</h2><p><img src="C:\Users\26411\Desktop\blog\source_posts\学习分享\Kafka【2】核心原理.assets\clip_image002.png" alt="img"></p><ol><li>producer 先从 zookeeper 的     “&#x2F;brokers&#x2F;…&#x2F;state”节点找到该 partition 的 leader ；</li><li>producer 将消息发送给该 leader ；</li><li>leader 将消息写入本地 log ；</li><li>followers 从 leader pull 消息，写入本地 log 后向 leader 发送 ACK ；</li><li>leader 收到所有 ISR 中的 replication 的 ACK 后，增加 HW（high watermark，最后 commit offset）并向 producer 发送 ACK ；</li></ol><h2 id="消费消息"><a href="#消费消息" class="headerlink" title="消费消息"></a>消费消息</h2><p>consumer 采用 pull（拉）模式从 broker 中读取数据。</p><p>push（推）模式很难适应消费速率不同的消费者，因为消息发送速率是由 broker 决定的。 它的目标是尽可能以最快速度传递消息，但是这样很容易造成 consumer 来不及处理消息，典型的表现就是拒绝服务以及网络拥塞。而 pull 模式则可以根据 consumer 的消费能力以适当的速率消费消息。 </p><p>对于 Kafka 而言，pull 模式更合适，它可简化 broker 的设计，consumer 可自主控制消费 消息的速率，同时 consumer 可以自己控制消费方式——即可批量消费也可逐条消费，同时还能选择不同的提交方式从而实现不同的传输语义。 </p><p>pull 模式不足之处是，如果 kafka 没有数据，消费者可能会陷入循环中，一直等待数据 到达。为了避免这种情况，我们在我们的拉请求中有参数，允许消费者请求在等待数据到达 的“长轮询”中进行阻塞（并且可选地等待到给定的字节数，以确保大的传输大小）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-Kafka生产者幂等性原理&quot;&gt;&lt;a href=&quot;#1-Kafka生产者幂等性原理&quot; class=&quot;headerlink&quot; title=&quot;1. Kafka生产者幂等性原理&quot;&gt;&lt;/a&gt;1. Kafka生产者幂等性原理&lt;/h1&gt;&lt;p&gt;Kafka的Producer发送</summary>
      
    
    
    
    <category term="学习分享" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>负载均衡 | 常见算法初探</title>
    <link href="http://example.com/posts/e1d15606.html"/>
    <id>http://example.com/posts/e1d15606.html</id>
    <published>2024-01-26T08:57:13.098Z</published>
    <updated>2024-01-26T08:59:26.737Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-负载均衡算法分类"><a href="#1-负载均衡算法分类" class="headerlink" title="1. 负载均衡算法分类"></a>1. 负载均衡算法分类</h1><p>抛开技术细节、根据算法的期望可以大致分为以下几类</p><table><thead><tr><th align="left">类别</th><th align="left">期望描述</th></tr></thead><tbody><tr><td align="left">任务平分类</td><td align="left">将接受到的请求平均分发到服务器，”平均”不是特指绝对数值的平均，也可以是权重平均、动态权重平均</td></tr><tr><td align="left">Hash类</td><td align="left">根据请求的某些关键信息进行hash运算，将相同hash值的请求负载到同一RS。常见有源ip hash，uid hash</td></tr><tr><td align="left">响应优先类</td><td align="left">根据RS的响应时间调整请求分配</td></tr><tr><td align="left">系统负载优先类</td><td align="left">根据RS的CPU负载、IO使用率、网卡吞吐量等系统性能指标调整请求分配</td></tr></tbody></table><h1 id="2-常见负载均衡算法"><a href="#2-常见负载均衡算法" class="headerlink" title="2. 常见负载均衡算法"></a>2. 常见负载均衡算法</h1><h2 id="2-1-轮询"><a href="#2-1-轮询" class="headerlink" title="2.1 轮询"></a>2.1 轮询</h2><p>接收到的请求按照顺序轮流分配请求到服务器。轮询是一种最简单的负载均衡策略，不关心服务器实际性能与负载。   简单即是轮询的优点也是缺点</p><ul><li><p>优点</p><ul><li>简单，只依赖服务器与负载均衡系统的连接     感知服务器状态</li></ul></li><li><p>缺点</p><ul><li><p><strong>当服务器系统负载很高，或当服务器出现严重故障(bug)从而无法正常处理请求，但未跟负载均衡系统断开连接时，轮询策略依旧会将请求分配到异常的服务器</strong></p></li><li><p>不能根据服务器配置高低来分配请求</p></li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">AtomicInteger</span> <span class="variable">nextServerCounter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 轮询得到下一服务器下标</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> modulo 可用服务器数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getNext</span><span class="params">(<span class="type">int</span> modulo)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> ( ; ; ) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">current</span> <span class="operator">=</span> nextServerCounter.get();</span><br><span class="line">        <span class="type">int</span> <span class="variable">next</span> <span class="operator">=</span> (current + <span class="number">1</span>) % modulo;</span><br><span class="line">        <span class="keyword">if</span> (nextServerCounter.compareAndSet(current, next)) &#123;</span><br><span class="line">            <span class="keyword">return</span> next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-2-随机"><a href="#2-2-随机" class="headerlink" title="2.2 随机"></a>2.2 随机</h2><p>​    接收到的请求根据随机数分配请求到服务器。优缺点跟轮询类似</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="type">int</span> <span class="title function_">chooseRandomInt</span><span class="params">(<span class="type">int</span> serverCount)</span> &#123;  </span><br><span class="line"><span class="keyword">return</span> ThreadLocalRandom.current().nextInt(serverCount);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-3-加权轮询"><a href="#2-3-加权轮询" class="headerlink" title="2.3 加权轮询"></a>2.3 加权轮询</h2><p>针对轮询策略无法根据服务器处理能力高低分配请求的缺点，可以使用配置权重的方式来实现。</p><h2 id="2-4-动态加权轮询算法"><a href="#2-4-动态加权轮询算法" class="headerlink" title="2.4 动态加权轮询算法"></a>2.4 动态加权轮询算法</h2><p>通过分析固定周期内某台服务器请求的错误次数、成功次数来动态加减服务器权重。</p><h2 id="2-5-一致性Hash算法"><a href="#2-5-一致性Hash算法" class="headerlink" title="2.5 一致性Hash算法"></a>2.5 一致性Hash算法</h2><p>   根据请求的某些特定信息进行hash运算，将相同hash值分配到同一服务器。</p><ul><li>根据 uid&#x2F;session id hash，相同的用户会话会负载到相同的服务器</li><li>根据 client ip hash，相同的源设备负载到相同的服务器</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">choose</span><span class="params">(Object key, <span class="type">int</span> serverCount)</span> &#123;</span><br><span class="line"><span class="type">int</span> <span class="variable">hashcode</span> <span class="operator">=</span> key.hashCode();</span><br><span class="line">    <span class="type">int</span> <span class="variable">selectedIndex</span> <span class="operator">=</span> Hashing.consistentHash(hashcode, serverCount); <span class="comment">// 使用Guava的一致性哈希算法</span></span><br><span class="line">    <span class="keyword">return</span> selectedIndex;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-6-响应优先算法"><a href="#2-6-响应优先算法" class="headerlink" title="2.6 响应优先算法"></a>2.6 响应优先算法</h2><ul><li><p>响应优先算法是从客户端角度来选择服务器的算法，优先分配响应速度最快的服务器，通过这种方式让客户端能最快响应。</p></li><li><p>实现响应优先算法需要感知服务器状态，收集、维护响应时间这个维度信息。</p></li><li><p>复杂点：</p><ul><li><p>负载均衡系统需要收集、维护、分析每个服务器每次请求的响应时间。</p></li><li><p>为了减少收集、分析所有请求响应时间的性能消耗，可以使用采样方式来收集，但采样方式会减少准确率，同时也会带来实现复杂度。</p></li><li><p>还需要考虑会不会因为响应优先 而导致瞬间大量的请求同时请求到极少部分服务器，能否平滑的接受请求和转移</p></li></ul></li></ul><h2 id="2-7-系统负载优先算法"><a href="#2-7-系统负载优先算法" class="headerlink" title="2.7 系统负载优先算法"></a>2.7 系统负载优先算法</h2><ul><li><p>同响应优先算法一样，本质上系统负载优先算法也是通过感知服务器状态，将请求分配到负载最低的服务器。</p></li><li><p>不同的是系统负载优先是站在服务器角度来选择分配权重，且关心的是服务器CPU负载、I&#x2F;O使用率、网卡吞吐量、网络连接数等维度的状态。</p></li><li><p>不同的负载均衡系统会根据应用场景选择最关注的服务器状态。如CPU密集型系统关注CPU负载，I&#x2F;O密集型系统关注I&#x2F;O使用率，LVS关注连接数。</p></li><li><p>同响应优先算法一样，由于需要感知服务器状态，进行周期统计。需要对服务器和负载均衡系统都进行一定的开发才能实现，带来了较高的复杂度，容易出现隐蔽的bug或者由于设计不好而成为性能瓶颈。</p></li></ul><h2 id="2-8-总结"><a href="#2-8-总结" class="headerlink" title="2.8 总结"></a>2.8 总结</h2><p>一般的负载均衡算法无法处理服务器应用异常而未与负载均衡系统断开的场景。</p><p>响应优先算法和系统负载优先算法理论上可以解决上述问题。</p><p><strong>使用其余负载均衡算法的负载均衡系统可以引入类似的熔断降级等机制来对服务质量出现问题的服务器进行异常处理。</strong></p><p>下文预告： Nacos、Feign等常用组件使用的负载均衡算法&#x2F;策略</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-负载均衡算法分类&quot;&gt;&lt;a href=&quot;#1-负载均衡算法分类&quot; class=&quot;headerlink&quot; title=&quot;1. 负载均衡算法分类&quot;&gt;&lt;/a&gt;1. 负载均衡算法分类&lt;/h1&gt;&lt;p&gt;抛开技术细节、根据算法的期望可以大致分为以下几类&lt;/p&gt;
&lt;table&gt;</summary>
      
    
    
    
    <category term="学习分享" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>《大型网站技术架构》| 读书笔记 | 【1】演化发展</title>
    <link href="http://example.com/posts/4a17b157.html"/>
    <id>http://example.com/posts/4a17b157.html</id>
    <published>2024-01-23T16:46:30.877Z</published>
    <updated>2024-01-25T09:46:30.460Z</updated>
    
    <content type="html"><![CDATA[<p>书名:   《大型网站技术架构：核心原理与案例分析》</p><h3 id="大型网站软件系统的特点"><a href="#大型网站软件系统的特点" class="headerlink" title="大型网站软件系统的特点"></a>大型网站软件系统的特点</h3><ul><li><p><strong>高并发、大流量</strong></p><ul><li>指标：PV、UV、IP、交易额、在线用户数</li></ul></li><li><p><strong>高可用</strong></p><ul><li>系统不间断服务</li></ul></li><li><p><strong>海量数据</strong></p><ul><li>存储、管理海量数据</li></ul></li><li><p><strong>用户分布广泛、网络情况复杂</strong></p><ul><li>系统为全球用户服务，因网络等原因，系统需全球化部署，即海外多地建立机器集群</li></ul></li><li><p><strong>需求快速变更、发布频繁</strong></p></li><li><p><strong>渐进式发展</strong></p></li></ul><p>​<strong>大型网站的技术挑战主要来自于庞大的用户，高并发的访问和海量的数据，任何简单的业务一旦需要处理数以P计的数据和面向数以亿计的用户，问题就会变得很棘手。大型网站架构主要就是解决这类问题。</strong></p><h3 id="网站演化发展"><a href="#网站演化发展" class="headerlink" title="网站演化发展"></a>网站演化发展</h3><h4 id="阶段一-初始"><a href="#阶段一-初始" class="headerlink" title="阶段一  初始"></a>阶段一  初始</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240118195725752.png" alt="image-20240118195725752"></p><ul><li>应用程序、数据库、文件 通通都在一台服务器上</li></ul><h4 id="阶段二-应用服务和数据服务分离"><a href="#阶段二-应用服务和数据服务分离" class="headerlink" title="阶段二 应用服务和数据服务分离"></a>阶段二 应用服务和数据服务分离</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240118195708412.png" alt="image-20240118195708412"></p><ul><li><strong>问题：</strong> 用户多导致性能变差，数据多导致存储空间不足</li><li>应用数据和数据服务分离 &#x3D;&gt; 应用服务器、文件服务器、数据库服务器</li><li>三台服务器对硬件资源的要求各不相同<ul><li>应用服务器——应对大量的业务逻辑——更快更强的CPU</li><li>数据库服务器——快速的磁盘检索和数据缓存——更快的硬盘和更大的内存</li><li>文件服务器——存储大量用户的文件——更大的硬盘</li><li>应用和数据分离后，不同特性的服务器各司其职，提高了网站的并发能力和数据存储能力</li></ul></li></ul><h4 id="阶段三-使用缓存改善性能"><a href="#阶段三-使用缓存改善性能" class="headerlink" title="阶段三 使用缓存改善性能"></a>阶段三 使用缓存改善性能</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240118200309557.png" alt="image-20240118200309557"></p><ul><li><strong>问题：</strong>用户多，数据库压力太大，导致访问延迟，进而影响整个网站的性能，换句话说：<strong>数据库成为了系统瓶颈</strong></li><li>二八定律：80%的业务访问集中在20%的数据上</li><li>因此给这20%的数据缓存在内存中，理论上就可以减少数据库的访问压力，提高整个网站的数据访问速度。<ul><li>网站使用的缓存可以分为两种<ul><li>缓存在应用服务器上的本地缓存<ul><li>1、受应用服务器的内存限制</li><li>2、出现和应用程序争用内存的情况</li></ul></li><li>缓存在专门的分布式缓存服务器上的远程缓存——理论上可以做到不受内存容量限制<ul><li>1、集群的方式  （例如Redis的集群方式、Codis等）</li><li>2、大内存的服务器</li></ul></li></ul></li></ul></li></ul><h4 id="阶段四-使用应用服务器集群改善网站的并发处理能力"><a href="#阶段四-使用应用服务器集群改善网站的并发处理能力" class="headerlink" title="阶段四 使用应用服务器集群改善网站的并发处理能力"></a>阶段四 使用应用服务器集群改善网站的并发处理能力</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240119101020800.png" alt="image-20240119101020800"></p><ul><li><strong>问题</strong>：使用缓存后，数据访问压力得到有效缓解，但是单一应用服务区能够处理的请求连接有限，在网站高峰期，应用服务器成为整个网站的瓶颈。</li><li>通过负载均衡调度服务器，可将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多的用户，就在集群中加入更多的应用服务器，使应用服务器的负载压力不再成为整个网站的瓶颈。</li></ul><h4 id="阶段五-数据库读写分离"><a href="#阶段五-数据库读写分离" class="headerlink" title="阶段五 数据库读写分离"></a>阶段五 数据库读写分离</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240119101646523.png" alt="image-20240119101646523"></p><ul><li>应用服务器在写数据的时候，访问主数据库，主数据库通过主从复制机制，将数据更新同步到从数据库，这样当应用服务器读数据时，就可以通过从数据库获得数据。</li></ul><h4 id="阶段六-使用CDN和反向代理加速网站响应"><a href="#阶段六-使用CDN和反向代理加速网站响应" class="headerlink" title="阶段六 使用CDN和反向代理加速网站响应"></a>阶段六 使用CDN和反向代理加速网站响应</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240119102905980.png" alt="image-20240119102905980"></p><ul><li><strong>问题</strong>：全球网络情况复杂，网站访问延迟，用户流失</li><li>CDN (内容分发网络) 的作用<ul><li>通过在多个地理位置建立一个入网点或一组CDN边缘服务器来工作<ul><li>缓存</li><li>动态加速(优化CDN服务器与应用服务器的连接)</li><li>边缘逻辑计算</li></ul></li></ul></li><li>反向代理的作用<ul><li>负载均衡，根据访问流量和服务器负载情况，将请求分发到不同的应用服务器</li><li>缓存</li><li>保护服务器，隐藏服务器真实 IP</li></ul></li><li>目的：都是为了尽早返回数据(缓存)给用户，同时也减轻了后端服务器的负载压力</li></ul><h4 id="阶段七-使用分布式文件系统和分布式数据库系统"><a href="#阶段七-使用分布式文件系统和分布式数据库系统" class="headerlink" title="阶段七 使用分布式文件系统和分布式数据库系统"></a>阶段七 使用分布式文件系统和分布式数据库系统</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240119104722478.png" alt="image-20240119104722478"></p><ul><li><strong>问题：</strong>一台数据库&#x2F;文件服务器是满足不了持续增长的业务需求的。</li><li>分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。</li><li>网站更常用的数据库拆分手段是业务分库，即将不同业务的数据库部署在不同的物理服务器上。</li></ul><h4 id="阶段八-使用NoSQL和搜索引擎"><a href="#阶段八-使用NoSQL和搜索引擎" class="headerlink" title="阶段八 使用NoSQL和搜索引擎"></a>阶段八 使用NoSQL和搜索引擎</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240119105539838.png" alt="image-20240119105539838"></p><ul><li><strong>问题：</strong>网站的业务越来越复杂，对数据存储和检索的需求也越来越复杂</li><li>网站需要采用一些非关系型数据库技术(Redis、MongoDB)、非数据库查询技术如搜索引擎（ES）</li><li>应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦</li></ul><h4 id="阶段九-业务拆分-分布式服务"><a href="#阶段九-业务拆分-分布式服务" class="headerlink" title="阶段九 业务拆分-分布式服务"></a>阶段九 业务拆分-分布式服务</h4><p><img src="C:\Users\Administrator\Desktop\读书笔记\《大型网站技术架构：核心原理与案例分析》读书笔记.assets\image-20240119110456687.png" alt="image-20240119110456687"></p><ul><li>问题：日益复杂的业务场景</li><li>使用分而治之的手段将整个网站业务分成不同的产品线<ul><li>例如大型购物交易网站会将 首页、商铺、订单、买家、卖家等拆分为不同的产品线，分归不同的业务团队负责</li></ul></li><li>技术上，会根据不同的产品线，将网站拆分为多个应用，每个应用独立部署维护<ul><li>应用之间可以通过访问同一个数据存储系统构成一个关联的完整的系统。</li></ul></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>大型网站的架构演化到这里，基本上大多数的技术问题都得以解决</p><ul><li>另外还有一些跨数据中心的实时数据同步问题  可以通过组合改进现有技术架构或引入新技术组件解决</li><li>如何把自己已经解决的问题的方案应用到别的业务上去 — 建设云计算平台，将计算作为一种基础资源出售，企业按需付费，另外存储、网络都可以按需购买。</li><li><strong>理解已成熟的网站架构技术方案的来龙去脉和历史渊源，在技术选型和架构决策才能有的放矢，直击要害。</strong></li></ul><h5 id="价值观"><a href="#价值观" class="headerlink" title="价值观"></a>价值观</h5><ul><li>没有哪个网站从诞生就是大型网站 (庞大用户、海量数据、高并发访问)，大型网站都是从小型网站发展而来的。</li><li>网站的价值在于它能为用户提供什么价值，而不是网站怎么做的，用了什么高级技术，否则就是舍本逐末。</li><li>驱动大型网站技术发展的主要力量是网站的业务发展，业务成就了技术，不要为了技术而技术。</li><li>当出现技术架构解决不了的问题时，可以看看是否是业务架构有问题。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;书名:   《大型网站技术架构：核心原理与案例分析》&lt;/p&gt;
&lt;h3 id=&quot;大型网站软件系统的特点&quot;&gt;&lt;a href=&quot;#大型网站软件系统的特点&quot; class=&quot;headerlink&quot; title=&quot;大型网站软件系统的特点&quot;&gt;&lt;/a&gt;大型网站软件系统的特点&lt;/h3&gt;&lt;ul</summary>
      
    
    
    
    <category term="读书笔记" scheme="http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka |【1】核心概念</title>
    <link href="http://example.com/posts/4a17b158.html"/>
    <id>http://example.com/posts/4a17b158.html</id>
    <published>2024-01-21T05:03:16.503Z</published>
    <updated>2024-01-28T08:23:15.367Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Kafka的应用场景"><a href="#1-Kafka的应用场景" class="headerlink" title="1. Kafka的应用场景"></a>1. Kafka的应用场景</h1><p>我们通常将 Kafka 用在两类程序：</p><ol><li><p>建立实时数据管道，以可靠地在系统或应用程序之间获取数据</p></li><li><p>构建实时流应用程序（对接流式计算框架），以转换或响应数据流</p></li><li><p>消息队列 (系统解耦、流量削峰、数据分发)</p><ul><li>系统解耦：<ul><li><strong>系统的耦合性越高，容错性就越低。</strong>以电商应用为例，用户创建订单后，<strong>如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常</strong>，影响用户使用体验。</li><li><strong>使用消息队列解耦合，系统的耦合性就会降低了。</strong>比如<strong>物流系统发生故障，需要几分钟才能来修复，在这段时间内，物流系统要处理的数据被缓存到消息队列中</strong>，用户的下单<strong>操作正常完成</strong>。当物流系统恢复后，补充处理存在消息队列中的订单消息即可，<strong>终端系统感知不到物流系统发生过几分钟故障</strong>。</li></ul></li><li>流量削峰<ul><li>应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了<strong>消息队列可以将大量请求缓存起来</strong>，<strong>分散到很长一段时间处理</strong>，这样可以大大提到系统的稳定性和用户体验。</li><li>一般情况，为了保证系统的稳定性，如果系统负载超过阈值，就会阻止用户请求，这会影响用户体验，而如果<strong>使用消息队列将请求缓存起来，等待系统处理完毕后通知用户下单完毕，这样总不能下单体验要好</strong>。</li><li>处于经济考量目的：<strong>业务系统正常时段的QPS如果是1000，流量最高峰是10000，为了应对流量最高峰而配置高性能的服务器显然不划算，这时可以使用消息队列对峰值流量削峰</strong></li></ul></li><li>数据分发<ul><li><strong>通过消息队列可以让数据在多个系统更加之间进行流通</strong>。<strong>数据的产生方不需要关心谁来使用数据，只需要将数据发送到消息队列</strong>，数据使<strong>用方直接在消息队列中直接获取数据</strong>即可</li></ul></li></ul></li><li><p>结合其他组件做日志处理</p></li></ol><img src="Kafka.assets\clip_image002.jpg" alt="img" style="zoom:50%;" /><p>上图，我们可以看到：</p><ol><li><p>Producers：可以有很多的应用程序，将消息数据放入到 Kafka 集群中。</p></li><li><p>Consumers：可以有很多的应用程序，将消息数据从 Kafka 集群中拉取出来。</p></li><li><p>Connectors：Kafka 的连接器可以将数据库中的数据导入到 Kafka，也可以将 Kafka 的数据导出到</p></li></ol><p>数据库中。</p><ol start="4"><li>Stream Processors：流处理器可以Kafka中拉取数据，也可以将数据写入到Kafka中。</li></ol><h1 id="2-Kafka-Java-Api-基础开发"><a href="#2-Kafka-Java-Api-基础开发" class="headerlink" title="2. Kafka-Java-Api(基础开发)"></a>2. Kafka-Java-Api(基础开发)</h1><h3 id="生产者程序开发"><a href="#生产者程序开发" class="headerlink" title="生产者程序开发"></a>生产者程序开发</h3><ol><li>创建连接<ul><li>bootstrap.servers：Kafka的服务器地址</li><li>acks：表示当生产者生产数据到Kafka中，Kafka中会以什么样的策略返回</li><li>key.serializer：Kafka中的消息是以key、value键值对存储的，而且生产者生产的消息是需要在网络上传到的，这里指定的是StringSerializer方式，就是以字符串方式发送（将来还可以使用其他的一些序列化框架：Google ProtoBuf、Avro）</li><li>value.serializer：同上</li></ul></li><li>创建一个生产者对象KafkaProducer</li><li>调用send方法发送消息（ProducerRecor，封装是key-value键值对）</li><li>调用Future.get表示等待服务端的响应</li><li>关闭生产者</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaProducerTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1. 创建用于连接Kafka的Properties配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node1.itcast.cn:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建一个生产者对象KafkaProducer</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 发送1-100的消息到指定的topic中</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">            <span class="comment">// 构建一条消息，直接new ProducerRecord</span></span><br><span class="line">            ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;test&quot;</span>, <span class="literal">null</span>, i + <span class="string">&quot;&quot;</span>);</span><br><span class="line">            Future&lt;RecordMetadata&gt; future = kafkaProducer.send(producerRecord);</span><br><span class="line">            <span class="comment">// 调用Future的get方法等待响应</span></span><br><span class="line">            future.get();</span><br><span class="line">            System.out.println(<span class="string">&quot;第&quot;</span> + i + <span class="string">&quot;条消息写入成功！&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.关闭生产者</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="消费者程序开发"><a href="#消费者程序开发" class="headerlink" title="消费者程序开发"></a>消费者程序开发</h3><ul><li>group.id：消费者组的概念，可以在一个消费组中包含多个消费者。如果若干个消费者的group.id是一样的，表示它们就在一个组中，一个组中的消费者是共同消费Kafka中topic的数据。</li><li>Kafka是一种拉消息模式的消息队列，在消费者中会有一个offset，表示从哪条消息开始拉取数据</li><li>kafkaConsumer.poll：Kafka的消费者API是一批一批数据的拉取</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者程序</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 1.创建Kafka消费者配置</span></span><br><span class="line"><span class="comment"> * Properties props = new Properties();</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;bootstrap.servers&quot;, &quot;node1.itcast.cn:9092&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;group.id&quot;, &quot;test&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;enable.auto.commit&quot;, &quot;true&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 2.创建Kafka消费者</span></span><br><span class="line"><span class="comment"> * 3.订阅要消费的主题</span></span><br><span class="line"><span class="comment"> * 4.使用一个while循环，不断从Kafka的topic中拉取消息</span></span><br><span class="line"><span class="comment"> * 5.将将记录（record）的offset、key、value都打印出来</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConsumerTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建Kafka消费者配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node1.itcast.cn:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 消费者组（可以使用消费者组将若干个消费者组织到一起），共同消费Kafka中topic的数据</span></span><br><span class="line">        <span class="comment">// 每一个消费者需要指定一个消费者组，如果消费者的组名是一样的，表示这几个消费者是一个组中的</span></span><br><span class="line">        props.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">        <span class="comment">// 自动提交offset</span></span><br><span class="line">        props.setProperty(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        <span class="comment">// 自动提交offset的时间间隔</span></span><br><span class="line">        props.setProperty(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line">        <span class="comment">// 拉取的key、value数据的</span></span><br><span class="line">        props.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.创建Kafka消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 订阅要消费的主题</span></span><br><span class="line">        <span class="comment">// 指定消费者从哪个topic中拉取数据</span></span><br><span class="line">        kafkaConsumer.subscribe(Arrays.asList(<span class="string">&quot;test&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.使用一个while循环，不断从Kafka的topic中拉取消息</span></span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// Kafka的消费者一次拉取一批的数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">5</span>));</span><br><span class="line">            <span class="comment">// 5.将将记录（record）的offset、key、value都打印出来</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                <span class="comment">// 主题</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> consumerRecord.topic();</span><br><span class="line">                <span class="comment">// offset：这条消息处于Kafka分区中的哪个位置</span></span><br><span class="line">                <span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> consumerRecord.offset();</span><br><span class="line">                <span class="comment">// key\value</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> consumerRecord.key();</span><br><span class="line">                <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> consumerRecord.value();</span><br><span class="line"></span><br><span class="line">                System.out.println(<span class="string">&quot;topic: &quot;</span> + topic + <span class="string">&quot; offset:&quot;</span> + offset + <span class="string">&quot; key:&quot;</span> + key + <span class="string">&quot; value:&quot;</span> + value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="生产者使用异步方式生产消息"><a href="#生产者使用异步方式生产消息" class="headerlink" title="生产者使用异步方式生产消息"></a>生产者使用异步方式生产消息</h3><ul><li>使用匿名内部类实现Callback接口，该接口中表示Kafka服务器响应给客户端，会自动调用onCompletion方法<ul><li>metadata：消息的元数据（属于哪个topic、属于哪个partition、对应的offset是什么）</li><li>exception：这个对象Kafka生产消息封装了出现的异常，如果为null，表示发送成功，如果不为null，表示出现异常。</li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 二、使用异步回调的方式发送消息</span></span><br><span class="line">ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;test&quot;</span>, <span class="literal">null</span>, i + <span class="string">&quot;&quot;</span>);</span><br><span class="line">kafkaProducer.send(producerRecord, <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">        <span class="comment">// 1. 判断发送消息是否成功</span></span><br><span class="line">        <span class="keyword">if</span>(exception == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 发送成功</span></span><br><span class="line">            <span class="comment">// 主题</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> metadata.topic();</span><br><span class="line">            <span class="comment">// 分区id</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> metadata.partition();</span><br><span class="line">            <span class="comment">// 偏移量</span></span><br><span class="line">            <span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> metadata.offset();</span><br><span class="line">            System.out.println(<span class="string">&quot;topic:&quot;</span> + topic + <span class="string">&quot; 分区id：&quot;</span> + partition + <span class="string">&quot; 偏移量：&quot;</span> + offset);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 发送出现错误</span></span><br><span class="line">            System.out.println(<span class="string">&quot;生产消息出现异常！&quot;</span>);</span><br><span class="line">            <span class="comment">// 打印异常消息</span></span><br><span class="line">            System.out.println(exception.getMessage());</span><br><span class="line">            <span class="comment">// 打印调用栈</span></span><br><span class="line">            System.out.println(exception.getStackTrace());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h1 id="3-Kafka的核心概念"><a href="#3-Kafka的核心概念" class="headerlink" title="3. Kafka的核心概念"></a>3. Kafka的核心概念</h1><h2 id="3-0-体系结构"><a href="#3-0-体系结构" class="headerlink" title="3.0 体系结构"></a>3.0 体系结构</h2><p>Kafka 体系结构如下所示：</p><p>Kafka 包含若干 Producer、若干 Broker、若干 Consumer 以及一个 Zookeeper 集群。</p><ul><li>Zookeeper 是 Kafka 用来负责集群元数据管理、控制器选举等操作的。</li><li>Producer 是负责将消息发送到 Broker 的。</li><li>Broker 负责接受消息，将消息持久化到磁盘。</li><li>Consumer 是负责从 Broker 订阅并消费消息。</li></ul><p><img src="/Kafka.assets%5Cimage-20240125181422937.png" alt="image-20240125181422937"></p><h2 id="3-1-Broker"><a href="#3-1-Broker" class="headerlink" title="3.1 Broker"></a>3.1 Broker</h2><ul><li><p>一个Kafka的集群通常由多个Broker组成，这样才能实现负载均衡、以及容错</p></li><li><p>Broker是<strong>无状态（Sateless）</strong>的，它们是通过ZooKeeper来维护集群状态</p></li><li><p>一个Kafka的Broker每秒可以处理数十万次读写，每个Broker都可以处理TB消息而不影响性能</p></li></ul><h2 id="3-2-Zookeeper"><a href="#3-2-Zookeeper" class="headerlink" title="3.2 Zookeeper"></a>3.2 Zookeeper</h2><ul><li><p>ZK用来管理和协调broker，并且存储了Kafka的元数据（例如：有多少topic、partition、consumer、producer）</p></li><li><p>ZK服务主要用于通知生产者和消费者Kafka集群中有新的Broker加入、或者Kafka集群中出现故障的Broker。</p></li></ul><p>PS：Kafka正在逐步想办法将ZooKeeper剥离，维护两套集群成本较高，社区提出KIP-500就是要替换掉ZooKeeper的依赖。“Kafka on Kafka”——Kafka自己来管理自己的元数据</p><h2 id="3-3-Topic"><a href="#3-3-Topic" class="headerlink" title="3.3 Topic"></a>3.3 Topic</h2><p>Kafka中Topic是一个逻辑概念</p><ul><li>所谓发布订阅机制<ul><li>生产者发布的消息是需要指定一个Topic的，含义即这个消息属于这个“主题”Topic，也可以把“主题”理解为“类别”，生产者就会把消息发送到所指定的Topic。</li><li>通常一个Topic中只会专门存储某一类的（消息）信息，比如 Topic（A）专门存储用户观看直播时长信息、Topic（B）专门存储直播PK开始信息。并且在一个Topic中的消息是有固定结构的。</li><li>消费者拉取的消息，是从消费者所指定需要订阅的 “主题”Topic 中去拉取的。</li></ul></li><li>一个主题Topic被分成多个Partition分区</li></ul><h2 id="3-4-Partition"><a href="#3-4-Partition" class="headerlink" title="3.4 Partition"></a>3.4 Partition</h2><img src="Kafka.assets\image-20240125201839746.png" alt="image-20240125201839746" style="zoom:50%;" /><p>一个主题Topic被分成多个Partition分区（Topic是逻辑概念，即无实体的）</p><ul><li><p>Partition分区 是最小的存储单元，掌握着一个Topic的部分数据。</p></li><li><p>每个Partition分区都是一个单独的 log 文件，每条记录都以追加的形式写入。</p></li><li><p>一个Topic的所有Partition分区是分布在多个不同的Broker中的</p><ul><li><p>原因一</p><ul><li><p>刚刚说到一个Topic被分成多个Partition分区，前面又提到一个Topic中存储的就是某一类消息（假设为A类消息）</p><p>那么假设一个场景，有很多个消费者需要消费A类消息，它要去哪里获取消息进行消费呢？</p><p> — 显然数据的来源是： Broker 中的 Partition分区 (log文件)</p><p>那么假设有三个Broker（B1、B2、B3），其上存在很多Partition，如果一个Topic的所有Partition都存储在 B1 中</p><p>此时所有消费者都来 B1 中获取A类消息。</p><p>如果B1宕机了，又因为只有B1上才拥有这个Topic的所有Partition，即A类信息只存于B1上。</p><p>此时这些消费者就无法读取到信息了。</p></li><li><p>但是如果一个Topic的很多Partition分区是分布在多个不同的Broker中的话，那么即使B1宕机了，在B2中也存在这个Topic的Partition，此时消费者可以到B2获取这类信息消费。</p></li></ul></li><li><p>原因二</p><ul><li>如果把一个Topic的所有Partition都放在一个Broker上，那么这个Topic消息的消费能力将会受限于一个Broker的IO能力</li></ul></li><li><p>总而言之，把一个Topic的所有Partition放在不同的Broker上，可以提高容错率、提高消息的消费能力。</p></li></ul></li><li><p>一个Partition会生成多个副本Replica，并且把它们分散存储在不同的Broker中</p><ul><li>刚刚解释了为什么一个Topic中的所有Partition要分布在不同的Broker上，但是还有一个问题，因为所有的Partition的并集数据才是全量数据，假设某个Broker宕机了，在这个Broker上存在P0分区，此时P0分区所拥有的消息就无法被读取了。且P0分区所拥有的消息是唯一的。</li><li>因此此时副本就出现了，一个Partition复制多份副本，分散存储在不同的Broker中，此时如果某Broker宕机了，但在其上的P0分区的消息并不是唯一的，在其他未宕机的Broker中有P0分区副本，依然可以获取P0分区的消息。</li><li>在Kafka中，一般都会设计副本Replica的个数 &gt; 1</li></ul></li></ul><h2 id="3-5-Offset"><a href="#3-5-Offset" class="headerlink" title="3.5 Offset"></a>3.5 Offset</h2><h3 id="3-5-1-Offset-的定义"><a href="#3-5-1-Offset-的定义" class="headerlink" title="3.5.1 Offset 的定义"></a>3.5.1 Offset 的定义</h3><ul><li>Offset 是一个递增的、不可变的数字，当一条记录写入 Partition 的时候，它就被追加到该 Partition 对应的 log 文件的末尾，并被分配一个序号，作为 Offset。即使消息被删除或过期，Offset 也不会改变或重用。</li><li><strong>Offset 是 Kafka 为每条消息分配的一个唯一的编号，它表示消息在分区中的顺序位置</strong>。</li><li>Offset 是从 0 开始的，每当有新的消息写入 Partition 时，Offset 就会加 1。</li></ul><h3 id="3-5-2-Offset-的作用"><a href="#3-5-2-Offset-的作用" class="headerlink" title="3.5.2 Offset 的作用"></a>3.5.2 Offset 的作用</h3><ul><li>offset 的作用主要有两个：<ul><li>一是用来定位消息。<strong>通过指定 offset，消费者可以准确地找到分区中的某条消息，或者从某个位置开始消费消息</strong>。</li><li>二是用来<strong>记录消费进度</strong>。消费者在消费完一条消息后，需要提交 offset 来告诉 Kafka broker 自己消费到哪里了。这样，如果消费者发生故障或重启，它可以根据保存的 offset 来恢复消费状态。</li></ul></li></ul><h3 id="3-5-3-Offset-的存储"><a href="#3-5-3-Offset-的存储" class="headerlink" title="3.5.3 Offset 的存储"></a>3.5.3 Offset 的存储</h3><ul><li><p>老版本默认Kafka将Offset存储在Zookeeper中</p></li><li><p>Kafka 0.9.0 版本后，offset 的实际存储位置都是在 Kafka 的一个内置主题中：consumer_offsets。这个主题有 50 个分区（可配置），每个分区存储一部分消费组（Consumer Group）的 offset 信息。Kafka broker 会根据消费组 ID 和主题名来计算出一个哈希值，并将其映射到 consumer_offsets 主题的某个分区上。</p><p>__consumer_offsets 主题是 Kafka 0.9.0 版本引入的新特性，之前的版本是将 offset 存储在 Zookeeper 中。但是 Zookeeper 不适合大量写入，因此后来改为存储在 Kafka 自身中，提高了性能和可靠性。</p></li></ul><h3 id="3-5-4-Offset-的提交和重置"><a href="#3-5-4-Offset-的提交和重置" class="headerlink" title="3.5.4 Offset 的提交和重置"></a>3.5.4 Offset 的提交和重置</h3><p>提交 offset 是消费者在消费完一条消息后，将当前消费的 offset 值更新到 Kafka broker 中的操作。提交 offset 的目的是为了记录消费进度，以便在消费者发生故障或重启时，能够从上次消费的位置继续消费。</p><p>重置 offset 是消费者在启动或运行过程中，将当前消费的 offset 值修改为其他值的操作。重置 offset 的目的是为了调整消费位置，以便在需要重新消费或跳过某些消息时，能够实现这个需求。</p><h4 id="提交-offset"><a href="#提交-offset" class="headerlink" title="提交 offset"></a>提交 offset</h4><p>消费者在消费 Kafka 消息时，需要维护</p><ul><li>当前消费的 offset 值，当前消费的 offset 值表示消费者正在消费的消息的位置，</li><li>已提交的 offset 值，已提交的 offset 值表示消费者已经跟Kafka确认了已消费过的消息的位置。</li></ul><p>消费者在消费完一条消息后，需要提交 offset 来更新已提交的 offset 值。提交 offset 的方式有两种：自动提交和手动提交。</p><ul><li>自动提交：Kafka 提供了一个配置参数 enable.auto.commit，默认为 true，表示开启自动提交功能。<strong>自动提交功能会在后台定期</strong>（由 auto.commit.interval.ms 参数控制）<strong>将当前消费的 offset 值提交给 Kafka broker。</strong></li><li>手动提交：如果 enable.auto.commit 设置为 false，则表示关闭自动提交功能，此时<strong>消费者需要手动调用 commitSync 或 commitAsync 方法来提交 offset。</strong>手动提交功能可以让消费者更灵活地控制何时以及如何提交 offset。</li></ul><p>需要注意的是，无论是自动提交还是手动提交，都不保证提交成功。因为 Kafka broker 可能发生故障或网络延迟，导致提交失败或延迟。因此，消费者需要处理提交失败或延迟的情况。</p><ul><li>提交失败：如果提交失败，消费者可以选择重试或放弃。重试的话，可能会导致多次提交同一个 offset 值，但是不会影响正确性，因为 Kafka broker 会忽略重复的 offset 值。放弃的话，可能会导致下次启动时重新消费已经消费过的消息。</li><li>提交延迟：如果提交延迟，消费者可以选择等待或继续。等待的话，可能会导致消费速度变慢，或者超过 session.timeout.ms 参数设置的时间而被认为已经死亡。继续的话，可能会导致下次启动时漏掉一些没有提交成功的消息。</li></ul><h4 id="重置-offset"><a href="#重置-offset" class="headerlink" title="重置 offset"></a>重置 offset</h4><p>重置 offset 的方式有两种：手动重置和自动重置。手动重置是指消费者主动调用 seek 或 seekToBeginning 或 seekToEnd 方法来修改当前消费的 offset 值。自动重置是指消费者在启动时根据 auto.offset.reset 参数来决定从哪个位置开始消费。</p><ul><li>手动重置：手动重置可以让消费者精确地控制从哪个位置开始消费。例如，如果想要重新消费某个分区的所有消息，可以调用 seekToBeginning 方法将 offset 设置为 0；如果想要跳过某个分区的所有消息，可以调用 seekToEnd 方法将 offset 设置为最大值；如果想要从某个具体的位置开始消费，可以调用 seek 方法将 offset 设置为任意值。</li><li>自动重置：自动重置可以让消费者在启动时根据 auto.offset.reset 参数来决定从哪个位置开始消费。auto.offset.reset 参数有三个可选值：earliest, latest 和 none。earliest 表示从最早的可用消息开始消费；latest 表示从最新的可用消息开始消费；none 表示如果没有可用的 offset，则抛出异常。</li></ul><h2 id="3-6-消费者组"><a href="#3-6-消费者组" class="headerlink" title="3.6 消费者组"></a>3.6 消费者组</h2><h3 id="3-6-1-案例说明"><a href="#3-6-1-案例说明" class="headerlink" title="3.6.1 案例说明"></a>3.6.1 案例说明</h3><ul><li><p>多个消费者，只要指定了相同的group_id，即属于同一个消费者组</p></li><li><p>同一个消费者组内的消费者可以共同消费一个Topic中的数据，但是一个Topic中是有很多Partition的，这是怎么理解呢</p><ul><li>例如有一个Topic，含有一个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B中只有一个消费者可以消费到消息，另外一个消费者将不会消费到消息。<ul><li><strong>这说明当一个消费者组内的消费者数量 &gt; 某Topic的Partition数量时，多余的消费者是会空闲的。</strong></li></ul></li><li>例如有一个Topic，含有两个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B会分别单独只消费某一个Partition，A和B不会交叉消费不同Partition。<ul><li><strong>这说明当一个消费者组内的消费者数量 &#x3D;&#x3D; 某Topic的Partition数量时，每个消费者对应一个Partition。</strong></li></ul></li><li>例如有一个Topic，含有三个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B会有一个消费者消费多个分区。<ul><li><strong>这说明当一个消费者组内的消费者数量 &lt; 某Topic的Partition数量时，部分消费者会消费多个Partition的消息。</strong></li></ul></li></ul></li><li><p>不同(多个)消费者组也可以共同消费同一个Topic中的数据。</p><ul><li>假设有两个消费者组A和B，都订阅了同一个Topic，这时候Topic的某一条消息，消费者组A和消费者组B都可以拉取到。即消费者组A会消费一次，消费者组B也会消费一次。消费组内具体的消费逻辑同上单个消费者组组内消费的逻辑。</li></ul></li></ul><h3 id="3-6-2-Partition和消费组内消费者数量"><a href="#3-6-2-Partition和消费组内消费者数量" class="headerlink" title="3.6.2 Partition和消费组内消费者数量"></a>3.6.2 Partition和消费组内消费者数量</h3><p>针对<strong>单个消费者组</strong>来说，</p><ul><li>若消费者数量大于partition数量，会造成闲置的消费者，产生浪费。</li><li>若消费者数量小于partition数量，会导致均衡失效，其中的某个或某些消费者会消费更多的任务。</li></ul><p>因此，一般消费组内消费者的数量应该等于Partition的数量；</p><p>但是如果需要消费的任务压力不大。也可以是第二种情况，即消费者的数量小于Partition数量。</p><h3 id="3-6-3-单播消费"><a href="#3-6-3-单播消费" class="headerlink" title="3.6.3 单播消费"></a>3.6.3 单播消费</h3><ul><li>让所有消费者处在同一个消费组里，消费组中的多个消费者只有一个消费者可以消费到Partition分区中的消息。</li><li>一条消息只能被某一个消费者消费。</li></ul><h3 id="3-6-4-多播消费"><a href="#3-6-4-多播消费" class="headerlink" title="3.6.4 多播消费"></a>3.6.4 多播消费</h3><ul><li><p>针对Kafka同一条消息只能被同一个消费组下的某一个消费者消费的特性，要实现多播只要保证这些消费者属于不同的消费组即可。</p></li><li><p>假设有两个消费者组A和B，结果是A消费者组和B消费者组中各有一个消费者成功消费到消息。</p></li><li><p>多播消费其实是一条消息能被多个消费者 (不同的消费者组) 消费的模式</p></li></ul><p>小贴士：</p><ul><li><p>Kafka是以消费者来 “拉”信息的模式工作的，而非“推”模式。</p></li><li><p>Kafka中存储的消息是以key、value形式存储的</p></li><li><p>通常一个Topic中只会专门存储某一类的（消息）信息，并且在一个Topic中的消息是有固定结构的</p></li><li><p>一个主题Topic中的所有Partition分区是分布在不同的Broker节点上的</p></li><li><p>请注意Offset的定义和作用</p></li><li><p>一般一个Topic被一个指定的消费者组消费，组中的消费者数量等于Partition数量。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-Kafka的应用场景&quot;&gt;&lt;a href=&quot;#1-Kafka的应用场景&quot; class=&quot;headerlink&quot; title=&quot;1. Kafka的应用场景&quot;&gt;&lt;/a&gt;1. Kafka的应用场景&lt;/h1&gt;&lt;p&gt;我们通常将 Kafka 用在两类程序：&lt;/p&gt;
&lt;ol&gt;</summary>
      
    
    
    
    <category term="学习分享" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>BIGO</title>
    <link href="http://example.com/posts/4a17b156.html"/>
    <id>http://example.com/posts/4a17b156.html</id>
    <published>2024-01-21T02:50:37.127Z</published>
    <updated>2024-01-21T02:54:09.555Z</updated>
    
    <content type="html"><![CDATA[<h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">&quot;My New Post&quot;</span></span><br></pre></td></tr></table></figure><p><a href="https://img1.imgtp.com/2024/01/20/iJ5eYrGh.jpg">https://img1.imgtp.com/2024/01/20/iJ5eYrGh.jpg</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#</summary>
      
    
    
    
    <category term="实习记录" scheme="http://example.com/categories/%E5%AE%9E%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    
    
  </entry>
  
</feed>
