<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>小黄的记录`Blog</title>
  
  <subtitle>天道酬勤</subtitle>
  <link href="http://example.com/atom.xml" rel="self"/>
  
  <link href="http://example.com/"/>
  <updated>2024-02-19T02:57:00.669Z</updated>
  <id>http://example.com/</id>
  
  <author>
    <name>小黄</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>Kafka |【2】核心原理</title>
    <link href="http://example.com/posts/acfeb110.html"/>
    <id>http://example.com/posts/acfeb110.html</id>
    <published>2024-01-28T08:21:41.359Z</published>
    <updated>2024-02-19T02:57:00.669Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Kafka生产者幂等性原理"><a href="#1-Kafka生产者幂等性原理" class="headerlink" title="1. Kafka生产者幂等性原理"></a>1. Kafka生产者幂等性原理</h1><p>Kafka的Producer发送消息时，Broker会返回ACK，Producer收到ACK才确认发送成功，否则会进行Retry，相当于Producer发送了两次一样的消息内容，此时可能有幂等性的问题 — <strong>导致生产者发送消息重复的问题</strong>。</p><p><img src="/Kafka%E3%80%902%E3%80%91%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86.assets%5Cimage-20240129120725088.png" alt="image-20240129120725088"></p><p>为了实现生产者的幂等性，Kafka引入了 Producer ID（PID）和 Sequence Number的概念。</p><ul><li><p>如果开启了这一项props.put(“enable.idempot”,true);，则Producer除了会发送消息，还会携带上PID和Seq</p></li><li><p>PID：每个Producer在初始化时，都会分配一个唯一的PID。</p></li><li><p>Sequence Number：针对每个PID（即针对生产者），发送到指定主题指定分区的消息都对应一个从0开始递增的Sequence Number</p></li></ul><p><img src="/Kafka%E3%80%902%E3%80%91%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86.assets%5Cimage-20240129120550120.png" alt="image-20240129120550120"></p><ul><li>通过这两个量，Broker去对同一个分区的同一个PID进行seq的大小判断，根据 《5》判断决定是否保存消息，保证幂等性。</li></ul><h1 id="2-生产者分区写入策略"><a href="#2-生产者分区写入策略" class="headerlink" title="2. 生产者分区写入策略"></a>2. 生产者分区写入策略</h1><p>生产者将消息发送到Topic (的Partition)，其实是Kafka依据不同的策略将数据分配到不同的分区中 (需要注意不同的分区是分配在不同的Broker上的)。</p><ul><li>轮询分区策略</li><li>随机分区策略</li><li>按key分区策略</li><li>自定义分区策略</li></ul><h3 id="轮询分区策略"><a href="#轮询分区策略" class="headerlink" title="轮询分区策略"></a>轮询分区策略</h3><img src="Kafka【2】核心原理.assets\image-20240129122432254.png" alt="image-20240129122432254" style="zoom:80%;" /><ul><li>默认的策略，也是使用的最多的策略，可以最大限度的保证所有消息平均分配到每一个分区</li><li>如果在生产消息的时候，key为null，则默认使用轮询算法。否则不会使用轮询。</li></ul><h3 id="随机分区策略"><a href="#随机分区策略" class="headerlink" title="随机分区策略"></a>随机分区策略</h3><p>随机把消息分配到Topic的分区，基本不用。</p><h3 id="按Key分区策略"><a href="#按Key分区策略" class="headerlink" title="按Key分区策略"></a>按Key分区策略</h3><img src="Kafka【2】核心原理.assets\image-20240129140918531.png" alt="image-20240129140918531" style="zoom:80%;" /><ul><li>key .hashcode  %  分区数量</li><li>如果消息有key值，那么会使用这个策略</li><li>可能会出现【数据倾斜】，例如某个Key包含了大量的数据，因为Key值一样，因此所有的数据都会分配到同一个分区，造成该分区的消息数量远大于其他分区。</li></ul><h4 id="消息有序性的问题"><a href="#消息有序性的问题" class="headerlink" title="消息有序性的问题"></a>消息有序性的问题</h4><p>使用轮询分区或随机分区，会导致一段连续的数据被打散存储到不同的Partition，导致消息消费的无序性。</p><p>Kafka的消息消费是全局乱序，局部Partition中的消息消费是有序的。</p><p>但是使用按Key分区策略，可以把一段连续的数据存储到同一个Partition，这样做到这一段数据的有序。但可能会造成数据倾斜。</p><p><img src="/Kafka%E3%80%902%E3%80%91%E6%A0%B8%E5%BF%83%E5%8E%9F%E7%90%86.assets%5Cimage-20240129143618068.png" alt="image-20240129143618068"></p><h3 id="自定义分区策略"><a href="#自定义分区策略" class="headerlink" title="自定义分区策略"></a>自定义分区策略</h3><p>自定义分区组件</p><p>在Kafka生产者配置中，指定使用自定义分区器的类名</p><h1 id="3-消费者组-Rebalance机制"><a href="#3-消费者组-Rebalance机制" class="headerlink" title="3. 消费者组 Rebalance机制"></a>3. 消费者组 Rebalance机制</h1><p>Kafka中的Rebalance称之为再均衡，是Kafka中确保消费者组下所有消费者如何达成一致，分配（订阅的Topic的）分区的机制</p><p><strong>Rebalance触发的时机有</strong>：</p><ul><li>消费者组中消费者的个数发送变化。例如有新的消费者加入消费者组，或者某个消费者停止了。</li><li>消费者组内订阅的Topic个数发生变化<ul><li>消费者可以订阅多个主题</li><li>假设当前的消费者组的三个消费者总共订阅了三个Topic，但有一个Topic突然被删除了，此时也需要发生再均衡。</li></ul></li></ul><img src="C:\Users\26411\Desktop\blog\source\_posts\学习分享\Kafka【2】核心原理.assets\image-20240129161506526.png" alt="image-20240129161506526" style="zoom: 67%;" /><ul><li>订阅的Topic的Partition个数发生变化，Partition的个数增加或减少</li></ul><img src="C:\Users\26411\Desktop\blog\source\_posts\学习分享\Kafka【2】核心原理.assets\image-20240129162130804.png" alt="image-20240129162130804" style="zoom:67%;" /><h2 id="Rebalance的不良影响"><a href="#Rebalance的不良影响" class="headerlink" title="Rebalance的不良影响"></a>Rebalance的不良影响</h2><ul><li>发生Rebalance的时候，消费者组下的所有消费者都会协调在一起共同参与，Kafka使用分配策略，尽可能达到最公平的分配。</li><li>Rebalance的过程会对消费者组产生非常严重的影响，Rebalance的过程中所有的消费者都将停止工作，直到Rebalance完成。</li></ul><h1 id="4-消费者分区分配策略"><a href="#4-消费者分区分配策略" class="headerlink" title="4. 消费者分区分配策略"></a>4. 消费者分区分配策略</h1><h2 id="Range范围分配策略"><a href="#Range范围分配策略" class="headerlink" title="Range范围分配策略"></a>Range范围分配策略</h2><ul><li>默认的分配策略</li></ul><p>需要注意这个分配策略是针对 某一单个Topic的。</p><p>例如消费者组订阅了两个Topic，那么针对这两个Topic，消费者组需要<strong>单独分别独立</strong>地走一下分配策略。</p><p>使用算法公式来决定每个消费者消费的分区范围</p><ul><li><p>n &#x3D; 分区数量 &#x2F; 消费者数量</p></li><li><p>m &#x3D; 分区数量 % 消费者数量</p></li><li><p>决策： 前m个消费者分别都消费n+1个分区；剩余消费者都消费n个分区</p></li></ul><p>例子1</p><p><img src="C:\Users\26411\Desktop\blog\source_posts\学习分享\Kafka【2】核心原理.assets\image-20240129170723422.png" alt="image-20240129170723422"></p><p>例子2</p><p><img src="C:\Users\26411\Desktop\blog\source_posts\学习分享\Kafka【2】核心原理.assets\image-20240129171026153.png" alt="image-20240129171026153"></p><h2 id="RoundRobin轮询策略"><a href="#RoundRobin轮询策略" class="headerlink" title="RoundRobin轮询策略"></a>RoundRobin轮询策略</h2><p>轮询策略是将消费者组内所有消费者以及消费者所订阅的<strong>所有Topic的所有Partition</strong>按照字典序排序（Topic和Partition的hashcode排序）</p><p>然后通过轮询的方式逐个将分区分配给每个消费者。</p><p><img src="C:\Users\26411\Desktop\blog\source_posts\学习分享\Kafka【2】核心原理.assets\image-20240129171502153.png" alt="image-20240129171502153"></p><h2 id="Stricky粘性分配策略"><a href="#Stricky粘性分配策略" class="headerlink" title="Stricky粘性分配策略"></a>Stricky粘性分配策略</h2><p>1、分区分配尽可能均匀</p><p>2、在发生rebalance的时候，分区的分配尽可能与上一次分配保持相同</p><p>3、没有发生rebalance时，分区的分配策略和RoundRobin轮询策略相似</p><p>在发生rebalance时，尽量保持原先消费者消费的partition不变（黏住上一次的分配），只是把有变化的部分尽量均匀的分配。</p><p>例如有三个消费者，共同消费6个分区，有一个消费者挂了，此时有两个分区空闲出来了没有消费者去消费。</p><p>此时进行rebalance，不要全部分区重新分配，只是把两个空闲的分区均匀分配给另外两个消费者，保留之前rebalance的分配结果。</p><p>可以明显减少系统资源的浪费，避免不必要的系统开销。</p><h1 id="5-副本机制"><a href="#5-副本机制" class="headerlink" title="5. 副本机制"></a>5. 副本机制</h1><p>副本的目的就是冗余备份，当某个Broker上的partition数据丢失，或者Broker宕机时，依然可以保证丢失的数据可用，因为在其他的Broker上的副本是可用的。</p><h2 id="producer的acks参数"><a href="#producer的acks参数" class="headerlink" title="producer的acks参数"></a>producer的acks参数</h2><p>对副本关系较大的就是，producer配置的acks参数了，acks参数表示当生产者生产消息时，写入到副本的要求严格程度，决定了Kafka在生产者生产消息这一 Part 如何在性能和可靠性之间做取舍。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">Properties props = new Properties();</span><br><span class="line">props.put(&quot;bootstrap.servers&quot;, &quot;node1.itcast.cn:9092&quot;);</span><br><span class="line">props.put(&quot;acks&quot;, &quot;all&quot;);// 生产者acks参数可配置为all、0、1、-1</span><br></pre></td></tr></table></figure><ul><li>acks配置为0<ul><li>生产者不等待broker确认，直接发送下一条数据，性能最高，但可能会存在数据丢失的情况，可靠性下降。</li></ul></li><li>acks配置为1<ul><li>生产者等待leader分区副本确认接收成功后，才会发送下一条数据</li></ul></li><li>acks配置为 -1 或 all<ul><li>生产者等待所有副本包括（follower分区副本）已经将数据同步后，才会发送下一条数据，性能最慢。可靠性最高。</li></ul></li></ul><p>这里提到leader分区和follower分区，需要注意，leader和follower的角色是针对partition来说的，并不是针对broker。</p><p>为了保证消费者消费的数据是一致的。Kafka规定只能从leader分区副本去读写消息，follower分区副本的意义就是冗余备份。</p><ul><li>针对只能从leader分区副本读写消息这一点，应该敏感的能意识到，leader分区一般会分布在不同的broker，也就是一个Broker不应该有超出常规的多个leader（不能出现leader分区倾斜），因为这样意味着这个broker负载会很高，因为只能在leader分区读写消息。</li></ul><h1 id="6-高层API和底层API"><a href="#6-高层API和底层API" class="headerlink" title="6. 高层API和底层API"></a>6. 高层API和底层API</h1><ul><li>高层API就是直接让Kafka帮助管理、处理分配、数据<ul><li>offset存储在ZK中</li><li>由kafka的rebalance来控制消费者分配的分区</li><li>开发起来比较简单，无需开发者关注底层细节</li><li>无法做到细粒度的控制</li></ul></li><li>低级API：由编写的程序自己控制逻辑<ul><li>自己来管理Offset，可以将offset存储在ZK、MySQL、Redis、Flink的状态存储</li><li>指定消费者拉取某个分区的数据</li><li>可以做到细粒度的控制</li><li>原有的Kafka的策略会失效，需要我们自己来实现消费机制</li></ul></li></ul><h1 id="7-分区的leader与follower"><a href="#7-分区的leader与follower" class="headerlink" title="7. 分区的leader与follower"></a>7. 分区的leader与follower</h1><p>leader和follower是针对分区partition来说的。不是针对broker。</p><p>在Kafka中，每个Topic可以配置多个Partition，而每个Partiton可以冗余多个副本(包括自身也称为副本)。</p><p>每个Partition存多份副本，  分为至少一个leader分区副本和（0-多个）follower分区副本。</p><h2 id="Leader的分配"><a href="#Leader的分配" class="headerlink" title="Leader的分配"></a>Leader的分配</h2><p>在创建Topic时，Kafka会将每个Partiton的leader分区副本均匀分配在每个Broker（因为规定了leader分区副本是读写消息的）这样可以使得Broker的负载尽量均衡。如果某个Broker有多个leader分区副本，这个Broker的负载会很高。</p><h2 id="follower的作用"><a href="#follower的作用" class="headerlink" title="follower的作用"></a>follower的作用</h2><p>所有的follower只会复制leader的日志数据文件，副本冗余（同步）</p><p>如果leader出现故障，其他的follower会被选举为leader</p><h2 id="AR、ISR、OSR"><a href="#AR、ISR、OSR" class="headerlink" title="AR、ISR、OSR"></a>AR、ISR、OSR</h2><p>在实际环境中，leader分区副本所在的Broker，有可能会出现一些故障，所以Kafka一定会选举出新的leader分区副本(在新的Broker)。</p><p>在讲解leader选举之前，我们先要明确几个概念。Kafka中，把follower可以按照不同状态分为三类——AR、ISR、OSR。</p><ul><li>分区的所有副本称为 「AR」（Assigned Replicas——已分配的副本）</li><li>所有与leader副本保持一定程度同步的副本（包括 leader 副本在内）组成 「ISR」（In-Sync Replicas——在同步中的副本）</li><li>由于follower副本同步滞后过多的副本（不包括 leader 副本）组成 「OSR」（Out-of-Sync Replias）</li><li>AR &#x3D; ISR + OSR</li><li>正常情况下，所有的follower副本都应该与leader副本保持同步，即AR &#x3D; ISR，OSR集合为空。</li></ul><h2 id="Leader选举"><a href="#Leader选举" class="headerlink" title="Leader选举"></a>Leader选举</h2><p>leader对于消息的写入以及读取是非常关键的，此时有两个疑问：</p><ol><li><p>Kafka如何确定某个partition是leader、哪个partition是follower呢？</p></li><li><p>某个leader崩溃了，如何快速确定另外一个leader呢？因为Kafka的吞吐量很高、延迟很低，所以选举leader必须非常快</p></li></ol><h3 id="Controller"><a href="#Controller" class="headerlink" title="Controller"></a>Controller</h3><ul><li><p>Kafka启动时，会在所有的broker中选择一个controller</p></li><li><p>前面leader和follower是针对partition，而controller是针对broker的</p></li><li><p>创建topic、或者添加分区、修改副本数量之类的管理任务都是由controller完成的</p></li><li><p>Kafka分区leader的选举，也是由controller决定的</p></li></ul><p><strong>Controller的选举</strong></p><ul><li>在Kafka集群启动的时候，每个broker都会尝试去ZooKeeper上注册成为Controller（ZK临时节点）</li><li>但只有一个竞争成功，其他的broker会注册该节点的监视器</li><li>一旦临时节点状态发生变化，就可以进行相应的处理</li><li>Controller也是高可用的，一旦某个broker崩溃，其他的broker会重新注册为Controller</li></ul><h3 id="Controller选举partition-leader"><a href="#Controller选举partition-leader" class="headerlink" title="Controller选举partition leader"></a>Controller选举partition leader</h3><ul><li>所有Partition的leader选举都由controller决定</li><li>controller会将leader的改变直接通过RPC的方式通知需为此作出响应的Broker</li><li>controller读取到当前分区的ISR，只要有一个Replica还幸存，就选择其中一个作为leader。否则，则任意选一个Replica作为leader</li><li>如果该partition的所有Replica都已经宕机，则新的leader为-1</li></ul><p><strong>为什么不能通过ZK的方式来选举partition的leader？</strong></p><ul><li>Kafka集群如果业务很多的情况下，会有很多的partition</li><li>假设某个broker宕机，就会出现很多的partiton都需要重新选举leader</li><li>如果使用zookeeper选举leader，会给zookeeper带来巨大的压力。所以，kafka中leader的选举不能使用ZK来实现</li></ul><p>小结：</p><p>Controller是通过ZK来进行选举的，是针对Broker的一个角色</p><p>Leader是通过ISR来选举的，是针对Partition的一个角色</p><h2 id="Leader的负载均衡"><a href="#Leader的负载均衡" class="headerlink" title="Leader的负载均衡"></a>Leader的负载均衡</h2><ul><li>如果某个broker crash之后，就可能会导致partition的leader分布不均匀，就是一个broker上存在一个topic下<strong>多个不同partition</strong>的leader</li><li>通过指令，可以将leader副本重新负载均衡到不同的broker上</li></ul><h1 id="8-Kafka生产和消费数据工作流程"><a href="#8-Kafka生产和消费数据工作流程" class="headerlink" title="8.Kafka生产和消费数据工作流程"></a>8.Kafka生产和消费数据工作流程</h1><h2 id="生产消息"><a href="#生产消息" class="headerlink" title="生产消息"></a>生产消息</h2><p><img src="C:\Users\26411\Desktop\blog\source_posts\学习分享\Kafka【2】核心原理.assets\clip_image002.png" alt="img"></p><ol><li>producer 先从 zookeeper 的     “&#x2F;brokers&#x2F;topic&#x2F;主题名&#x2F;partitions&#x2F;分区名&#x2F;state”节点找到该 partition 的 leader ；</li><li>producer 将消息发送给该 leader ；</li><li>leader 将消息写入本地 log ；</li><li>followers 从 leader pull 消息，写入本地 log 后向 leader 发送 ACK ；</li><li>leader 收到所有 ISR 中的 replica 的 ACK 后，并向 producer 发送 ACK ；</li></ol><h2 id="消费消息"><a href="#消费消息" class="headerlink" title="消费消息"></a>消费消息</h2><ul><li>kafka采用拉取模型，由消费者自己记录消费状态，每个消费者互相独立地顺序拉取每个分区的消息</li><li>消费者可以按照任意的顺序消费消息。比如，消费者可以重置到旧的偏移量，重新处理之前已经消费过的消息；或者直接跳到最近的位置，从当前的时刻开始消费。</li></ul><img src="C:\Users\26411\Desktop\blog\source\_posts\学习分享\Kafka【2】核心原理.assets\image-20240218171830411.png" alt="image-20240218171830411" style="zoom:80%;" /><ul><li>每个consumer都可以根据分配策略（默认RangeAssignor），获得要消费的分区</li><li>获取到consumer对应的offset（默认从ZK中获取上一次消费的offset）</li><li>找到该分区的leader，拉取数据</li><li>消费者提交offset</li></ul><h1 id="9-Kafka的数据存储形式"><a href="#9-Kafka的数据存储形式" class="headerlink" title="9.Kafka的数据存储形式"></a>9.Kafka的数据存储形式</h1>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-Kafka生产者幂等性原理&quot;&gt;&lt;a href=&quot;#1-Kafka生产者幂等性原理&quot; class=&quot;headerlink&quot; title=&quot;1. Kafka生产者幂等性原理&quot;&gt;&lt;/a&gt;1. Kafka生产者幂等性原理&lt;/h1&gt;&lt;p&gt;Kafka的Producer发送</summary>
      
    
    
    
    <category term="学习分享" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>负载均衡 | 常见算法初探</title>
    <link href="http://example.com/posts/e1d15606.html"/>
    <id>http://example.com/posts/e1d15606.html</id>
    <published>2024-01-26T08:57:13.098Z</published>
    <updated>2024-01-30T05:08:07.388Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-负载均衡算法分类"><a href="#1-负载均衡算法分类" class="headerlink" title="1. 负载均衡算法分类"></a>1. 负载均衡算法分类</h1><p>抛开技术细节、根据算法的期望可以大致分为以下几类</p><table><thead><tr><th align="left">类别</th><th align="left">期望描述</th></tr></thead><tbody><tr><td align="left">任务平分类</td><td align="left">将接受到的请求平均分发到服务器，”平均”不是特指绝对数值的平均，也可以是权重平均、动态权重平均</td></tr><tr><td align="left">Hash类</td><td align="left">根据请求的某些关键信息进行hash运算，将相同hash值的请求负载到同一RS。常见有源ip hash，uid hash</td></tr><tr><td align="left">响应优先类</td><td align="left">根据RS的响应时间调整请求分配</td></tr><tr><td align="left">系统负载优先类</td><td align="left">根据RS的CPU负载、IO使用率、网卡吞吐量等系统性能指标调整请求分配</td></tr></tbody></table><h1 id="2-常见负载均衡算法"><a href="#2-常见负载均衡算法" class="headerlink" title="2. 常见负载均衡算法"></a>2. 常见负载均衡算法</h1><h2 id="2-1-轮询"><a href="#2-1-轮询" class="headerlink" title="2.1 轮询"></a>2.1 轮询</h2><p>接收到的请求按照顺序轮流分配请求到服务器。轮询是一种最简单的负载均衡策略，不关心服务器实际性能与负载。   简单即是轮询的优点也是缺点</p><ul><li><p>优点</p><ul><li>简单，只依赖服务器与负载均衡系统的连接     感知服务器状态</li></ul></li><li><p>缺点</p><ul><li><p><strong>当服务器系统负载很高，或当服务器出现严重故障(bug)从而无法正常处理请求，但未跟负载均衡系统断开连接时，轮询策略依旧会将请求分配到异常的服务器</strong></p></li><li><p>不能根据服务器配置高低来分配请求</p></li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">private</span> <span class="type">AtomicInteger</span> <span class="variable">nextServerCounter</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">AtomicInteger</span>(<span class="number">0</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 轮询得到下一服务器下标</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@param</span> modulo 可用服务器数</span></span><br><span class="line"><span class="comment"> * <span class="doctag">@return</span></span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">getNext</span><span class="params">(<span class="type">int</span> modulo)</span> &#123;</span><br><span class="line">    <span class="keyword">for</span> ( ; ; ) &#123;</span><br><span class="line">        <span class="type">int</span> <span class="variable">current</span> <span class="operator">=</span> nextServerCounter.get();</span><br><span class="line">        <span class="type">int</span> <span class="variable">next</span> <span class="operator">=</span> (current + <span class="number">1</span>) % modulo;</span><br><span class="line">        <span class="keyword">if</span> (nextServerCounter.compareAndSet(current, next)) &#123;</span><br><span class="line">            <span class="keyword">return</span> next;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-2-随机"><a href="#2-2-随机" class="headerlink" title="2.2 随机"></a>2.2 随机</h2><p>​    接收到的请求根据随机数分配请求到服务器。优缺点跟轮询类似</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">protected</span> <span class="type">int</span> <span class="title function_">chooseRandomInt</span><span class="params">(<span class="type">int</span> serverCount)</span> &#123;  </span><br><span class="line"><span class="keyword">return</span> ThreadLocalRandom.current().nextInt(serverCount);</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-3-加权轮询"><a href="#2-3-加权轮询" class="headerlink" title="2.3 加权轮询"></a>2.3 加权轮询</h2><p>针对轮询策略无法根据服务器处理能力高低分配请求的缺点，可以使用配置权重的方式来实现。</p><h2 id="2-4-动态加权轮询算法"><a href="#2-4-动态加权轮询算法" class="headerlink" title="2.4 动态加权轮询算法"></a>2.4 动态加权轮询算法</h2><p>通过分析固定周期内某台服务器请求的错误次数、成功次数来动态加减服务器权重。</p><h2 id="2-5-一致性Hash算法"><a href="#2-5-一致性Hash算法" class="headerlink" title="2.5 一致性Hash算法"></a>2.5 一致性Hash算法</h2><p>   根据请求的某些特定信息进行hash运算，将相同hash值分配到同一服务器。</p><ul><li>根据 uid&#x2F;session id hash，相同的用户会话会负载到相同的服务器</li><li>根据 client ip hash，相同的源设备负载到相同的服务器</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="type">int</span> <span class="title function_">choose</span><span class="params">(Object key, <span class="type">int</span> serverCount)</span> &#123;</span><br><span class="line"><span class="type">int</span> <span class="variable">hashcode</span> <span class="operator">=</span> key.hashCode();</span><br><span class="line">    <span class="type">int</span> <span class="variable">selectedIndex</span> <span class="operator">=</span> Hashing.consistentHash(hashcode, serverCount); <span class="comment">// 使用Guava的一致性哈希算法</span></span><br><span class="line">    <span class="keyword">return</span> selectedIndex;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="2-6-响应优先算法"><a href="#2-6-响应优先算法" class="headerlink" title="2.6 响应优先算法"></a>2.6 响应优先算法</h2><ul><li><p>响应优先算法是从客户端角度来选择服务器的算法，优先分配响应速度最快的服务器，通过这种方式让客户端能最快响应。</p></li><li><p>实现响应优先算法需要感知服务器状态，收集、维护响应时间这个维度信息。</p></li><li><p>复杂点：</p><ul><li><p>负载均衡系统需要收集、维护、分析每个服务器每次请求的响应时间。</p></li><li><p>为了减少收集、分析所有请求响应时间的性能消耗，可以使用采样方式来收集，但采样方式会减少准确率，同时也会带来实现复杂度。</p></li><li><p>还需要考虑会不会因为响应优先 而导致瞬间大量的请求同时请求到极少部分服务器，能否平滑的接受请求和转移</p></li></ul></li></ul><h2 id="2-7-系统负载优先算法"><a href="#2-7-系统负载优先算法" class="headerlink" title="2.7 系统负载优先算法"></a>2.7 系统负载优先算法</h2><ul><li><p>同响应优先算法一样，本质上系统负载优先算法也是通过感知服务器状态，将请求分配到负载最低的服务器。</p></li><li><p>不同的是系统负载优先是站在服务器角度来选择分配权重，且关心的是服务器CPU负载、I&#x2F;O使用率、网卡吞吐量、网络连接数等维度的状态。</p></li><li><p>不同的负载均衡系统会根据应用场景选择最关注的服务器状态。如CPU密集型系统关注CPU负载，I&#x2F;O密集型系统关注I&#x2F;O使用率，LVS关注连接数。</p></li><li><p>同响应优先算法一样，由于需要感知服务器状态，进行周期统计。需要对服务器和负载均衡系统都进行一定的开发才能实现，带来了较高的复杂度，容易出现隐蔽的bug或者由于设计不好而成为性能瓶颈。</p></li></ul><h2 id="2-8-总结"><a href="#2-8-总结" class="headerlink" title="2.8 总结"></a>2.8 总结</h2><p>一般的负载均衡算法无法处理服务器应用异常而未与负载均衡系统断开的场景。</p><p>响应优先算法和系统负载优先算法理论上可以解决上述问题。</p><p><strong>使用其余负载均衡算法的负载均衡系统可以引入类似的熔断降级等机制来对服务质量出现问题的服务器进行异常处理。</strong></p><p>下文预告： Nacos、Feign等常用组件使用的负载均衡算法&#x2F;策略</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-负载均衡算法分类&quot;&gt;&lt;a href=&quot;#1-负载均衡算法分类&quot; class=&quot;headerlink&quot; title=&quot;1. 负载均衡算法分类&quot;&gt;&lt;/a&gt;1. 负载均衡算法分类&lt;/h1&gt;&lt;p&gt;抛开技术细节、根据算法的期望可以大致分为以下几类&lt;/p&gt;
&lt;table&gt;</summary>
      
    
    
    
    <category term="学习分享" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>Kafka |【1】核心概念</title>
    <link href="http://example.com/posts/4a17b158.html"/>
    <id>http://example.com/posts/4a17b158.html</id>
    <published>2024-01-21T05:03:16.503Z</published>
    <updated>2024-01-30T07:01:53.449Z</updated>
    
    <content type="html"><![CDATA[<h1 id="1-Kafka的应用场景"><a href="#1-Kafka的应用场景" class="headerlink" title="1. Kafka的应用场景"></a>1. Kafka的应用场景</h1><p>我们通常将 Kafka 用在两类程序：</p><ol><li><p>建立实时数据管道，以可靠地在系统或应用程序之间获取数据</p></li><li><p>构建实时流应用程序（对接流式计算框架），以转换或响应数据流</p></li><li><p>消息队列 (系统解耦、流量削峰、数据分发)</p><ul><li>系统解耦：<ul><li><strong>系统的耦合性越高，容错性就越低。</strong>以电商应用为例，用户创建订单后，<strong>如果耦合调用库存系统、物流系统、支付系统，任何一个子系统出了故障或者因为升级等原因暂时不可用，都会造成下单操作异常</strong>，影响用户使用体验。</li><li><strong>使用消息队列解耦合，系统的耦合性就会降低了。</strong>比如<strong>物流系统发生故障，需要几分钟才能来修复，在这段时间内，物流系统要处理的数据被缓存到消息队列中</strong>，用户的下单<strong>操作正常完成</strong>。当物流系统恢复后，补充处理存在消息队列中的订单消息即可，<strong>终端系统感知不到物流系统发生过几分钟故障</strong>。</li></ul></li><li>流量削峰<ul><li>应用系统如果遇到系统请求流量的瞬间猛增，有可能会将系统压垮。有了<strong>消息队列可以将大量请求缓存起来</strong>，<strong>分散到很长一段时间处理</strong>，这样可以大大提到系统的稳定性和用户体验。</li><li>一般情况，为了保证系统的稳定性，如果系统负载超过阈值，就会阻止用户请求，这会影响用户体验，而如果<strong>使用消息队列将请求缓存起来，等待系统处理完毕后通知用户下单完毕，这样总不能下单体验要好</strong>。</li><li>处于经济考量目的：<strong>业务系统正常时段的QPS如果是1000，流量最高峰是10000，为了应对流量最高峰而配置高性能的服务器显然不划算，这时可以使用消息队列对峰值流量削峰</strong></li></ul></li><li>数据分发<ul><li><strong>通过消息队列可以让数据在多个系统更加之间进行流通</strong>。<strong>数据的产生方不需要关心谁来使用数据，只需要将数据发送到消息队列</strong>，数据使<strong>用方直接在消息队列中直接获取数据</strong>即可</li></ul></li></ul></li><li><p>结合其他组件做日志处理</p></li></ol><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/clip_image002.jpg" style="zoom:60%;" /><p>上图，我们可以看到：</p><ol><li><p>Producers：可以有很多的应用程序，将消息数据放入到 Kafka 集群中。</p></li><li><p>Consumers：可以有很多的应用程序，将消息数据从 Kafka 集群中拉取出来。</p></li><li><p>Connectors：Kafka 的连接器可以将数据库中的数据导入到 Kafka，也可以将 Kafka 的数据导出到</p></li></ol><p>数据库中。</p><ol start="4"><li>Stream Processors：流处理器可以Kafka中拉取数据，也可以将数据写入到Kafka中。</li></ol><h1 id="2-Kafka-Java-Api-基础开发"><a href="#2-Kafka-Java-Api-基础开发" class="headerlink" title="2. Kafka-Java-Api(基础开发)"></a>2. Kafka-Java-Api(基础开发)</h1><h3 id="生产者程序开发"><a href="#生产者程序开发" class="headerlink" title="生产者程序开发"></a>生产者程序开发</h3><ol><li>创建连接<ul><li>bootstrap.servers：Kafka的服务器地址</li><li>acks：表示当生产者生产数据到Kafka中，Kafka中会以什么样的策略返回</li><li>key.serializer：Kafka中的消息是以key、value键值对存储的，而且生产者生产的消息是需要在网络上传到的，这里指定的是StringSerializer方式，就是以字符串方式发送（将来还可以使用其他的一些序列化框架：Google ProtoBuf、Avro）</li><li>value.serializer：同上</li></ul></li><li>创建一个生产者对象KafkaProducer</li><li>调用send方法发送消息（ProducerRecor，封装是key-value键值对）</li><li>调用Future.get表示等待服务端的响应</li><li>关闭生产者</li></ol><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaProducerTest</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> ExecutionException, InterruptedException &#123;</span><br><span class="line">        <span class="comment">// 1. 创建用于连接Kafka的Properties配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.put(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node1.itcast.cn:9092&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;acks&quot;</span>, <span class="string">&quot;all&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;key.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line">        props.put(<span class="string">&quot;value.serializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringSerializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2. 创建一个生产者对象KafkaProducer</span></span><br><span class="line">        KafkaProducer&lt;String, String&gt; kafkaProducer = <span class="keyword">new</span> <span class="title class_">KafkaProducer</span>&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 发送1-100的消息到指定的topic中</span></span><br><span class="line">        <span class="keyword">for</span>(<span class="type">int</span> <span class="variable">i</span> <span class="operator">=</span> <span class="number">0</span>; i &lt; <span class="number">100</span>; ++i) &#123;</span><br><span class="line">            <span class="comment">// 构建一条消息，直接new ProducerRecord</span></span><br><span class="line">            ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;test&quot;</span>, <span class="literal">null</span>, i + <span class="string">&quot;&quot;</span>);</span><br><span class="line">            Future&lt;RecordMetadata&gt; future = kafkaProducer.send(producerRecord);</span><br><span class="line">            <span class="comment">// 调用Future的get方法等待响应</span></span><br><span class="line">            future.get();</span><br><span class="line">            System.out.println(<span class="string">&quot;第&quot;</span> + i + <span class="string">&quot;条消息写入成功！&quot;</span>);</span><br><span class="line">        &#125;</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.关闭生产者</span></span><br><span class="line">        kafkaProducer.close();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h3 id="消费者程序开发"><a href="#消费者程序开发" class="headerlink" title="消费者程序开发"></a>消费者程序开发</h3><ul><li>group.id：消费者组的概念，可以在一个消费组中包含多个消费者。如果若干个消费者的group.id是一样的，表示它们就在一个组中，一个组中的消费者是共同消费Kafka中topic的数据。</li><li>Kafka是一种拉消息模式的消息队列，在消费者中会有一个offset，表示从哪条消息开始拉取数据</li><li>kafkaConsumer.poll：Kafka的消费者API是一批一批数据的拉取</li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/**</span></span><br><span class="line"><span class="comment"> * 消费者程序</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 1.创建Kafka消费者配置</span></span><br><span class="line"><span class="comment"> * Properties props = new Properties();</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;bootstrap.servers&quot;, &quot;node1.itcast.cn:9092&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;group.id&quot;, &quot;test&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;enable.auto.commit&quot;, &quot;true&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span></span><br><span class="line"><span class="comment"> * props.setProperty(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);</span></span><br><span class="line"><span class="comment"> *</span></span><br><span class="line"><span class="comment"> * 2.创建Kafka消费者</span></span><br><span class="line"><span class="comment"> * 3.订阅要消费的主题</span></span><br><span class="line"><span class="comment"> * 4.使用一个while循环，不断从Kafka的topic中拉取消息</span></span><br><span class="line"><span class="comment"> * 5.将将记录（record）的offset、key、value都打印出来</span></span><br><span class="line"><span class="comment"> */</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">KafkaConsumerTest</span> &#123;</span><br><span class="line"></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="comment">// 1.创建Kafka消费者配置</span></span><br><span class="line">        <span class="type">Properties</span> <span class="variable">props</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Properties</span>();</span><br><span class="line">        props.setProperty(<span class="string">&quot;bootstrap.servers&quot;</span>, <span class="string">&quot;node1.itcast.cn:9092&quot;</span>);</span><br><span class="line">        <span class="comment">// 消费者组（可以使用消费者组将若干个消费者组织到一起），共同消费Kafka中topic的数据</span></span><br><span class="line">        <span class="comment">// 每一个消费者需要指定一个消费者组，如果消费者的组名是一样的，表示这几个消费者是一个组中的</span></span><br><span class="line">        props.setProperty(<span class="string">&quot;group.id&quot;</span>, <span class="string">&quot;test&quot;</span>);</span><br><span class="line">        <span class="comment">// 自动提交offset</span></span><br><span class="line">        props.setProperty(<span class="string">&quot;enable.auto.commit&quot;</span>, <span class="string">&quot;true&quot;</span>);</span><br><span class="line">        <span class="comment">// 自动提交offset的时间间隔</span></span><br><span class="line">        props.setProperty(<span class="string">&quot;auto.commit.interval.ms&quot;</span>, <span class="string">&quot;1000&quot;</span>);</span><br><span class="line">        <span class="comment">// 拉取的key、value数据的</span></span><br><span class="line">        props.setProperty(<span class="string">&quot;key.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line">        props.setProperty(<span class="string">&quot;value.deserializer&quot;</span>, <span class="string">&quot;org.apache.kafka.common.serialization.StringDeserializer&quot;</span>);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 2.创建Kafka消费者</span></span><br><span class="line">        KafkaConsumer&lt;String, String&gt; kafkaConsumer = <span class="keyword">new</span> <span class="title class_">KafkaConsumer</span>&lt;&gt;(props);</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 3. 订阅要消费的主题</span></span><br><span class="line">        <span class="comment">// 指定消费者从哪个topic中拉取数据</span></span><br><span class="line">        kafkaConsumer.subscribe(Arrays.asList(<span class="string">&quot;test&quot;</span>));</span><br><span class="line"></span><br><span class="line">        <span class="comment">// 4.使用一个while循环，不断从Kafka的topic中拉取消息</span></span><br><span class="line">        <span class="keyword">while</span>(<span class="literal">true</span>) &#123;</span><br><span class="line">            <span class="comment">// Kafka的消费者一次拉取一批的数据</span></span><br><span class="line">            ConsumerRecords&lt;String, String&gt; consumerRecords = kafkaConsumer.poll(Duration.ofSeconds(<span class="number">5</span>));</span><br><span class="line">            <span class="comment">// 5.将将记录（record）的offset、key、value都打印出来</span></span><br><span class="line">            <span class="keyword">for</span> (ConsumerRecord&lt;String, String&gt; consumerRecord : consumerRecords) &#123;</span><br><span class="line">                <span class="comment">// 主题</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> consumerRecord.topic();</span><br><span class="line">                <span class="comment">// offset：这条消息处于Kafka分区中的哪个位置</span></span><br><span class="line">                <span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> consumerRecord.offset();</span><br><span class="line">                <span class="comment">// key\value</span></span><br><span class="line">                <span class="type">String</span> <span class="variable">key</span> <span class="operator">=</span> consumerRecord.key();</span><br><span class="line">                <span class="type">String</span> <span class="variable">value</span> <span class="operator">=</span> consumerRecord.value();</span><br><span class="line"></span><br><span class="line">                System.out.println(<span class="string">&quot;topic: &quot;</span> + topic + <span class="string">&quot; offset:&quot;</span> + offset + <span class="string">&quot; key:&quot;</span> + key + <span class="string">&quot; value:&quot;</span> + value);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="生产者使用异步方式生产消息"><a href="#生产者使用异步方式生产消息" class="headerlink" title="生产者使用异步方式生产消息"></a>生产者使用异步方式生产消息</h3><ul><li>使用匿名内部类实现Callback接口，该接口中表示Kafka服务器响应给客户端，会自动调用onCompletion方法<ul><li>metadata：消息的元数据（属于哪个topic、属于哪个partition、对应的offset是什么）</li><li>exception：这个对象Kafka生产消息封装了出现的异常，如果为null，表示发送成功，如果不为null，表示出现异常。</li></ul></li></ul><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">// 二、使用异步回调的方式发送消息</span></span><br><span class="line">ProducerRecord&lt;String, String&gt; producerRecord = <span class="keyword">new</span> <span class="title class_">ProducerRecord</span>&lt;&gt;(<span class="string">&quot;test&quot;</span>, <span class="literal">null</span>, i + <span class="string">&quot;&quot;</span>);</span><br><span class="line">kafkaProducer.send(producerRecord, <span class="keyword">new</span> <span class="title class_">Callback</span>() &#123;</span><br><span class="line">    <span class="meta">@Override</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">onCompletion</span><span class="params">(RecordMetadata metadata, Exception exception)</span> &#123;</span><br><span class="line">        <span class="comment">// 1. 判断发送消息是否成功</span></span><br><span class="line">        <span class="keyword">if</span>(exception == <span class="literal">null</span>) &#123;</span><br><span class="line">            <span class="comment">// 发送成功</span></span><br><span class="line">            <span class="comment">// 主题</span></span><br><span class="line">            <span class="type">String</span> <span class="variable">topic</span> <span class="operator">=</span> metadata.topic();</span><br><span class="line">            <span class="comment">// 分区id</span></span><br><span class="line">            <span class="type">int</span> <span class="variable">partition</span> <span class="operator">=</span> metadata.partition();</span><br><span class="line">            <span class="comment">// 偏移量</span></span><br><span class="line">            <span class="type">long</span> <span class="variable">offset</span> <span class="operator">=</span> metadata.offset();</span><br><span class="line">            System.out.println(<span class="string">&quot;topic:&quot;</span> + topic + <span class="string">&quot; 分区id：&quot;</span> + partition + <span class="string">&quot; 偏移量：&quot;</span> + offset);</span><br><span class="line">        &#125;</span><br><span class="line">        <span class="keyword">else</span> &#123;</span><br><span class="line">            <span class="comment">// 发送出现错误</span></span><br><span class="line">            System.out.println(<span class="string">&quot;生产消息出现异常！&quot;</span>);</span><br><span class="line">            <span class="comment">// 打印异常消息</span></span><br><span class="line">            System.out.println(exception.getMessage());</span><br><span class="line">            <span class="comment">// 打印调用栈</span></span><br><span class="line">            System.out.println(exception.getStackTrace());</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">&#125;);</span><br></pre></td></tr></table></figure><h1 id="3-Kafka的核心概念"><a href="#3-Kafka的核心概念" class="headerlink" title="3. Kafka的核心概念"></a>3. Kafka的核心概念</h1><h2 id="3-0-体系结构"><a href="#3-0-体系结构" class="headerlink" title="3.0 体系结构"></a>3.0 体系结构</h2><p>Kafka 体系结构如下所示：</p><p>Kafka 包含若干 Producer、若干 Broker、若干 Consumer 以及一个 Zookeeper 集群。</p><ul><li>Zookeeper 是 Kafka 用来负责集群元数据管理、控制器选举等操作的。</li><li>Producer 是负责将消息发送到 Broker 的。</li><li>Broker 负责接受消息，将消息持久化到磁盘。</li><li>Consumer 是负责从 Broker 订阅并消费消息。</li></ul><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240125181422937.png"></p><h2 id="3-1-Broker"><a href="#3-1-Broker" class="headerlink" title="3.1 Broker"></a>3.1 Broker</h2><ul><li><p>一个Kafka的集群通常由多个Broker组成，这样才能实现负载均衡、以及容错</p></li><li><p>Broker是<strong>无状态（Sateless）</strong>的，它们是通过ZooKeeper来维护集群状态</p></li><li><p>一个Kafka的Broker每秒可以处理数十万次读写，每个Broker都可以处理TB消息而不影响性能</p></li></ul><h2 id="3-2-Zookeeper"><a href="#3-2-Zookeeper" class="headerlink" title="3.2 Zookeeper"></a>3.2 Zookeeper</h2><ul><li><p>ZK用来管理和协调broker，并且存储了Kafka的元数据（例如：有多少topic、partition、consumer、producer）</p></li><li><p>ZK服务主要用于通知生产者和消费者Kafka集群中有新的Broker加入、或者Kafka集群中出现故障的Broker。</p></li></ul><p>PS：Kafka正在逐步想办法将ZooKeeper剥离，维护两套集群成本较高，社区提出KIP-500就是要替换掉ZooKeeper的依赖。“Kafka on Kafka”——Kafka自己来管理自己的元数据</p><h2 id="3-3-Topic"><a href="#3-3-Topic" class="headerlink" title="3.3 Topic"></a>3.3 Topic</h2><p>Kafka中Topic是一个逻辑概念</p><ul><li>所谓发布订阅机制<ul><li>生产者发布的消息是需要指定一个Topic的，含义即这个消息属于这个“主题”Topic，也可以把“主题”理解为“类别”，生产者就会把消息发送到所指定的Topic。</li><li>通常一个Topic中只会专门存储某一类的（消息）信息，比如 Topic（A）专门存储用户观看直播时长信息、Topic（B）专门存储直播PK开始信息。并且在一个Topic中的消息是有固定结构的。</li><li>消费者拉取的消息，是从消费者所指定需要订阅的 “主题”Topic 中去拉取的。</li></ul></li><li>一个主题Topic被分成多个Partition分区</li></ul><h2 id="3-4-Partition"><a href="#3-4-Partition" class="headerlink" title="3.4 Partition"></a>3.4 Partition</h2><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240125201839746.png" style="zoom:75%;" /><p>一个主题Topic被分成多个Partition分区（Topic是逻辑概念，即无实体的）</p><ul><li><p>Partition分区 是最小的存储单元，掌握着一个Topic的部分数据。</p></li><li><p>每个Partition分区都是一个单独的 log 文件，每条记录都以追加的形式写入。</p></li><li><p>一个Topic的所有Partition分区是分布在多个不同的Broker中的</p><ul><li><p>原因一</p><ul><li><p>刚刚说到一个Topic被分成多个Partition分区，前面又提到一个Topic中存储的就是某一类消息（假设为A类消息）</p><p>那么假设一个场景，有很多个消费者需要消费A类消息，它要去哪里获取消息进行消费呢？</p><p> — 显然数据的来源是： Broker 中的 Partition分区 (log文件)</p><p>那么假设有三个Broker（B1、B2、B3），其上存在很多Partition，如果一个Topic的所有Partition都存储在 B1 中</p><p>此时所有消费者都来 B1 中获取A类消息。</p><p>如果B1宕机了，又因为只有B1上才拥有这个Topic的所有Partition，即A类信息只存于B1上。</p><p>此时这些消费者就无法读取到信息了。</p></li><li><p>但是如果一个Topic的很多Partition分区是分布在多个不同的Broker中的话，那么即使B1宕机了，在B2中也存在这个Topic的Partition，此时消费者可以到B2获取这类信息消费。</p></li></ul></li><li><p>原因二</p><ul><li>如果把一个Topic的所有Partition都放在一个Broker上，那么这个Topic消息的消费能力将会受限于一个Broker的IO能力</li></ul></li><li><p>总而言之，把一个Topic的所有Partition放在不同的Broker上，可以提高容错率、提高消息的消费能力。</p></li></ul></li><li><p>一个Partition会生成多个副本Replica，并且把它们分散存储在不同的Broker中</p><ul><li>刚刚解释了为什么一个Topic中的所有Partition要分布在不同的Broker上，但是还有一个问题，因为所有的Partition的并集数据才是全量数据，假设某个Broker宕机了，在这个Broker上存在P0分区，此时P0分区所拥有的消息就无法被读取了。且P0分区所拥有的消息是唯一的。</li><li>因此此时副本就出现了，一个Partition复制多份副本，分散存储在不同的Broker中，此时如果某Broker宕机了，但在其上的P0分区的消息并不是唯一的，在其他未宕机的Broker中有P0分区副本，依然可以获取P0分区的消息。</li><li>在Kafka中，一般都会设计副本Replica的个数 &gt; 1</li></ul></li></ul><h2 id="3-5-Offset"><a href="#3-5-Offset" class="headerlink" title="3.5 Offset"></a>3.5 Offset</h2><h3 id="3-5-1-Offset-的定义"><a href="#3-5-1-Offset-的定义" class="headerlink" title="3.5.1 Offset 的定义"></a>3.5.1 Offset 的定义</h3><ul><li>Offset 是一个递增的、不可变的数字，当一条记录写入 Partition 的时候，它就被追加到该 Partition 对应的 log 文件的末尾，并被分配一个序号，作为 Offset。即使消息被删除或过期，Offset 也不会改变或重用。</li><li><strong>Offset 是 Kafka 为每条消息分配的一个唯一的编号，它表示消息在分区中的顺序位置</strong>。</li><li>Offset 是从 0 开始的，每当有新的消息写入 Partition 时，Offset 就会加 1。</li></ul><h3 id="3-5-2-Offset-的作用"><a href="#3-5-2-Offset-的作用" class="headerlink" title="3.5.2 Offset 的作用"></a>3.5.2 Offset 的作用</h3><ul><li>offset 的作用主要有两个：<ul><li>一是用来定位消息。<strong>通过指定 offset，消费者可以准确地找到分区中的某条消息，或者从某个位置开始消费消息</strong>。</li><li>二是用来<strong>记录消费进度</strong>。消费者在消费完一条消息后，需要提交 offset 来告诉 Kafka broker 自己消费到哪里了。这样，如果消费者发生故障或重启，它可以根据保存的 offset 来恢复消费状态。</li></ul></li></ul><h3 id="3-5-3-Offset-的存储"><a href="#3-5-3-Offset-的存储" class="headerlink" title="3.5.3 Offset 的存储"></a>3.5.3 Offset 的存储</h3><ul><li><p>老版本默认Kafka将Offset存储在Zookeeper中</p></li><li><p>Kafka 0.9.0 版本后，offset 的实际存储位置都是在 Kafka 的一个内置主题中：consumer_offsets。这个主题有 50 个分区（可配置），每个分区存储一部分消费组（Consumer Group）的 offset 信息。Kafka broker 会根据消费组 ID 和主题名来计算出一个哈希值，并将其映射到 consumer_offsets 主题的某个分区上。</p><p>__consumer_offsets 主题是 Kafka 0.9.0 版本引入的新特性，之前的版本是将 offset 存储在 Zookeeper 中。但是 Zookeeper 不适合大量写入，因此后来改为存储在 Kafka 自身中，提高了性能和可靠性。</p></li></ul><h3 id="3-5-4-Offset-的提交和重置"><a href="#3-5-4-Offset-的提交和重置" class="headerlink" title="3.5.4 Offset 的提交和重置"></a>3.5.4 Offset 的提交和重置</h3><p>提交 offset 是消费者在消费完一条消息后，将当前消费的 offset 值更新到 Kafka broker 中的操作。提交 offset 的目的是为了记录消费进度，以便在消费者发生故障或重启时，能够从上次消费的位置继续消费。</p><p>重置 offset 是消费者在启动或运行过程中，将当前消费的 offset 值修改为其他值的操作。重置 offset 的目的是为了调整消费位置，以便在需要重新消费或跳过某些消息时，能够实现这个需求。</p><h4 id="提交-offset"><a href="#提交-offset" class="headerlink" title="提交 offset"></a>提交 offset</h4><p>消费者在消费 Kafka 消息时，需要维护</p><ul><li>当前消费的 offset 值，当前消费的 offset 值表示消费者正在消费的消息的位置，</li><li>已提交的 offset 值，已提交的 offset 值表示消费者已经跟Kafka确认了已消费过的消息的位置。</li></ul><p>消费者在消费完一条消息后，需要提交 offset 来更新已提交的 offset 值。提交 offset 的方式有两种：自动提交和手动提交。</p><ul><li>自动提交：Kafka 提供了一个配置参数 enable.auto.commit，默认为 true，表示开启自动提交功能。<strong>自动提交功能会在后台定期</strong>（由 auto.commit.interval.ms 参数控制）<strong>将当前消费的 offset 值提交给 Kafka broker。</strong></li><li>手动提交：如果 enable.auto.commit 设置为 false，则表示关闭自动提交功能，此时<strong>消费者需要手动调用 commitSync 或 commitAsync 方法来提交 offset。</strong>手动提交功能可以让消费者更灵活地控制何时以及如何提交 offset。</li></ul><p>需要注意的是，无论是自动提交还是手动提交，都不保证提交成功。因为 Kafka broker 可能发生故障或网络延迟，导致提交失败或延迟。因此，消费者需要处理提交失败或延迟的情况。</p><ul><li>提交失败：如果提交失败，消费者可以选择重试或放弃。重试的话，可能会导致多次提交同一个 offset 值，但是不会影响正确性，因为 Kafka broker 会忽略重复的 offset 值。放弃的话，可能会导致下次启动时重新消费已经消费过的消息。</li><li>提交延迟：如果提交延迟，消费者可以选择等待或继续。等待的话，可能会导致消费速度变慢，或者超过 session.timeout.ms 参数设置的时间而被认为已经死亡。继续的话，可能会导致下次启动时漏掉一些没有提交成功的消息。</li></ul><h4 id="重置-offset"><a href="#重置-offset" class="headerlink" title="重置 offset"></a>重置 offset</h4><p>重置 offset 的方式有两种：手动重置和自动重置。手动重置是指消费者主动调用 seek 或 seekToBeginning 或 seekToEnd 方法来修改当前消费的 offset 值。自动重置是指消费者在启动时根据 auto.offset.reset 参数来决定从哪个位置开始消费。</p><ul><li>手动重置：手动重置可以让消费者精确地控制从哪个位置开始消费。例如，如果想要重新消费某个分区的所有消息，可以调用 seekToBeginning 方法将 offset 设置为 0；如果想要跳过某个分区的所有消息，可以调用 seekToEnd 方法将 offset 设置为最大值；如果想要从某个具体的位置开始消费，可以调用 seek 方法将 offset 设置为任意值。</li><li>自动重置：自动重置可以让消费者在启动时根据 auto.offset.reset 参数来决定从哪个位置开始消费。auto.offset.reset 参数有三个可选值：earliest, latest 和 none。earliest 表示从最早的可用消息开始消费；latest 表示从最新的可用消息开始消费；none 表示如果没有可用的 offset，则抛出异常。</li></ul><h2 id="3-6-消费者组"><a href="#3-6-消费者组" class="headerlink" title="3.6 消费者组"></a>3.6 消费者组</h2><h3 id="3-6-1-案例说明"><a href="#3-6-1-案例说明" class="headerlink" title="3.6.1 案例说明"></a>3.6.1 案例说明</h3><ul><li><p>多个消费者，只要指定了相同的group_id，即属于同一个消费者组</p></li><li><p>同一个消费者组内的消费者可以共同消费一个Topic中的数据，但是一个Topic中是有很多Partition的，这是怎么理解呢</p><ul><li>例如有一个Topic，含有一个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B中只有一个消费者可以消费到消息，另外一个消费者将不会消费到消息。<ul><li><strong>这说明当一个消费者组内的消费者数量 &gt; 某Topic的Partition数量时，多余的消费者是会空闲的。</strong></li></ul></li><li>例如有一个Topic，含有两个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B会分别单独只消费某一个Partition，A和B不会交叉消费不同Partition。<ul><li><strong>这说明当一个消费者组内的消费者数量 &#x3D;&#x3D; 某Topic的Partition数量时，每个消费者对应一个Partition。</strong></li></ul></li><li>例如有一个Topic，含有三个Partition，有一个消费者组（有消费者A，B），此时消费者A和消费者B会有一个消费者消费多个分区。<ul><li><strong>这说明当一个消费者组内的消费者数量 &lt; 某Topic的Partition数量时，部分消费者会消费多个Partition的消息。</strong></li></ul></li></ul></li><li><p>不同(多个)消费者组也可以共同消费同一个Topic中的数据。</p><ul><li>假设有两个消费者组A和B，都订阅了同一个Topic，这时候Topic的某一条消息，消费者组A和消费者组B都可以拉取到。即消费者组A会消费一次，消费者组B也会消费一次。消费组内具体的消费逻辑同上单个消费者组组内消费的逻辑。</li></ul></li></ul><h3 id="3-6-2-Partition和消费组内消费者数量"><a href="#3-6-2-Partition和消费组内消费者数量" class="headerlink" title="3.6.2 Partition和消费组内消费者数量"></a>3.6.2 Partition和消费组内消费者数量</h3><p>针对<strong>单个消费者组</strong>来说，</p><ul><li>若消费者数量大于partition数量，会造成闲置的消费者，产生浪费。</li><li>若消费者数量小于partition数量，会导致均衡失效，其中的某个或某些消费者会消费更多的任务。</li></ul><p>因此，一般消费组内消费者的数量应该等于Partition的数量；</p><p>但是如果需要消费的任务压力不大。也可以是第二种情况，即消费者的数量小于Partition数量。</p><h3 id="3-6-3-单播消费"><a href="#3-6-3-单播消费" class="headerlink" title="3.6.3 单播消费"></a>3.6.3 单播消费</h3><ul><li>让所有消费者处在同一个消费组里，消费组中的多个消费者只有一个消费者可以消费到Partition分区中的消息。</li><li>一条消息只能被某一个消费者消费。</li></ul><h3 id="3-6-4-多播消费"><a href="#3-6-4-多播消费" class="headerlink" title="3.6.4 多播消费"></a>3.6.4 多播消费</h3><ul><li><p>针对Kafka同一条消息只能被同一个消费组下的某一个消费者消费的特性，要实现多播只要保证这些消费者属于不同的消费组即可。</p></li><li><p>假设有两个消费者组A和B，结果是A消费者组和B消费者组中各有一个消费者成功消费到消息。</p></li><li><p>多播消费其实是一条消息能被多个消费者 (不同的消费者组) 消费的模式</p></li></ul><p>小贴士：</p><ul><li><p>Kafka是以消费者来 “拉”信息的模式工作的，而非“推”模式。</p></li><li><p>Kafka中存储的消息是以key、value形式存储的</p></li><li><p>通常一个Topic中只会专门存储某一类的（消息）信息，并且在一个Topic中的消息是有固定结构的</p></li><li><p>一个主题Topic中的所有Partition分区是分布在不同的Broker节点上的</p></li><li><p>请注意Offset的定义和作用</p></li><li><p>一般一个Topic被一个指定的消费者组消费，组中的消费者数量等于Partition数量。</p></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;1-Kafka的应用场景&quot;&gt;&lt;a href=&quot;#1-Kafka的应用场景&quot; class=&quot;headerlink&quot; title=&quot;1. Kafka的应用场景&quot;&gt;&lt;/a&gt;1. Kafka的应用场景&lt;/h1&gt;&lt;p&gt;我们通常将 Kafka 用在两类程序：&lt;/p&gt;
&lt;ol&gt;</summary>
      
    
    
    
    <category term="学习分享" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>Tencent_Owner需求的模板规范</title>
    <link href="http://example.com/posts/4a17b156.html"/>
    <id>http://example.com/posts/4a17b156.html</id>
    <published>2024-01-21T02:50:37.127Z</published>
    <updated>2024-07-28T17:41:24.473Z</updated>
    
    <content type="html"><![CDATA[<h1 id="Owner需求的模板规范"><a href="#Owner需求的模板规范" class="headerlink" title="Owner需求的模板规范"></a>Owner需求的模板规范</h1><h2 id="Owner的意义-为什么要Owner"><a href="#Owner的意义-为什么要Owner" class="headerlink" title="Owner的意义,为什么要Owner?"></a>Owner的意义,为什么要Owner?</h2><p>一、我们会发现每个需求的实施，最好有一个Owner（当涉及到多方合作时更是如此）</p><p>1、Owner 把关整体节奏，把相关信息进行整合，并同步给相关干系人。</p><p>2、Owner 及时关注相关涉及方的进度和风险、并同步需求进度和风险，积极推进需求前进，保证需求有质量的按期交付。</p><p>二、Owner背后代表了某种责任，不同的同学可能Owner的范围不同，所以技术人的成长，从某种理解方面来说 本质上是不断提升自己Owner所覆盖的范围。</p><h2 id="Owner每个阶段应该做什么事情？"><a href="#Owner每个阶段应该做什么事情？" class="headerlink" title="Owner每个阶段应该做什么事情？"></a>Owner每个阶段应该做什么事情？</h2><p>从后台开发的视角来看，除了认真做好本职工作，还能做哪些事情，哪些行为来Owner需求？</p><p>一个需求的大致可分为：<strong>需求评审、（与合作方沟通、对齐技术方案）、评估需求工作量和排期、开发、联调、体验、测试、发布、外网使用</strong></p><p><strong>我梳理每个阶段的本职工作，以及Owner特殊应该做的事情(红字部分标注)：</strong></p><p>一、需求评审：</p><p>1、充分与产品同学进行沟通，明确需求单内容。</p><p>2、评估产品同学提出的需求方案的合理性，需求方案能否满足用户的需求，有无建议。</p><p>3、根据业务目前的技术情况，业务架构，初步评估需求中技术实现的可行性。</p><p>二、与合作方沟通、对齐技术方案</p><p>1、<font color="red"><strong>主动积极</strong></font>与合作方进行沟通，将核心技术方案和边界情况等讨论清楚，<font color="red"><strong>将结论同步</strong></font></p><p>三、评估需求工作量和排期</p><p>1、尽量准确评估自身开发的工作量。</p><p>2、<font color="red"><strong>关注涉及方的排期，涉及方的排期是否能跟上联调时间。</strong></font></p><p>四、开发</p><p>【本职开发】</p><p>1、<font color="red"><strong>如果遇到阻塞点、有风险点及时重点同步，看是否资源调配、升级处理；</strong></font></p><p><font color="red"><strong>若需第三方协助处理，此时应积极跟进、推动得出预期时间，再将结论同步。</strong></font></p><p><font color="red"><strong>得出预期时间后，应保持跟进状态，积极推动帮助解决问题，再将进度同步。</strong></font></p><p>2、<font color="red"><strong>若进度正常顺利，也定期同步，至少产品和PM应该知道进度。</strong></font></p><p>【涉及方开发】</p><p>1、<font color="red"><strong>关注涉及方的开发进度，若有进度过慢、有阻塞点的、有风险的情况，及时沟通同步。</strong></font></p><p>五、联调</p><p>1、<font color="red"><strong>同步联调进度。</strong></font></p><p>六、体验、测试、CR</p><p>1、关注跟进体验进度，<font color="red"><strong>积极推动进展</strong></font></p><p>2、关注跟进测试进度，<font color="red"><strong>积极推动进展</strong></font></p><p>3、跟进CR状态，及时修改CR问题，重新自测，以及和测试沟通是否需要重测哪些地方</p><p>七、发布</p><p>1、<font color="red"><strong>若涉及多方发布，沟通梳理发布计划，将发布计划同步</strong></font></p><p>2、细心谨慎发布和观察</p><p>八、外网使用</p><p>1、亲自体验功能</p><p>2、若有现网客诉问题，及时跟进排查解决并关注后续情况，解决方式和结论同步</p><p>上述多次提到，将沟通结论同步，将进度同步，将发布计划同步等等，同步的意义是什么，为什么需要同步：</p><p>1、保证无沟通Gap，避免沟通Gap带来的问题</p><p>2、保证重要性结论、进度、计划周知，方便相关干系人及时调整策略或资源</p><h2 id="如何锻炼并提升Owner的能力？"><a href="#如何锻炼并提升Owner的能力？" class="headerlink" title="如何锻炼并提升Owner的能力？"></a>如何锻炼并提升Owner的能力？</h2><h4 id="一、从小到大，循序渐进"><a href="#一、从小到大，循序渐进" class="headerlink" title="一、从小到大，循序渐进"></a>一、从小到大，循序渐进</h4><p>从 Owner成功 3,4 天的需求 ——&gt; Owner成功 半个月的需求 ——&gt; Owner成功 一个月的需求 ——&gt; …… 甚至到整个业务项目</p><h4 id=""><a href="#" class="headerlink" title=""></a></h4><h4 id="二、Owner的特质"><a href="#二、Owner的特质" class="headerlink" title="二、Owner的特质"></a>二、Owner的特质</h4><p>目前认为Owner的特质有三点</p><p>1、认真负责</p><p>这是工作底线，对我们的交付结果负责，每一个文档、每一行代码，都要对其质量负责。</p><p>2、积极主动</p><p>很多时候会有一些意料之外的情况发生，需要你去跟进处理，这时候就需要具备积极主动的精神和态度</p><p>（尽管有可能暂时你不知道怎么回答，不知道怎么解决处理，暂时没有时间处理），但这些都有对应的途径可以去推进，可以咨询他人，可以找到相关负责人帮助排查，可以定个时间专门处理，至少你要积极主动去推动问题的解决</p><p>3、善于总结和同步</p><p><font color="red"><strong>上述这些特质其实可以通过训练锻炼来达到，梳理以下步骤</strong></font></p><p>1、首先第一步是模仿，模仿Owner</p><p>2、其次是总结沉淀出一套Owner的工作模式、模板规范</p><p>3、按照总结的Owner工作模式、模板规范去不断实践</p><p>4、实践过程中迭代更新优化 模式和模板</p><p>5、变成了你本身自然的工作方式，自然而然就是具备了这三种特质。</p><h4 id="-1"><a href="#-1" class="headerlink" title=""></a></h4><h4 id="三、非Owner的行为，切记避免"><a href="#三、非Owner的行为，切记避免" class="headerlink" title="三、非Owner的行为，切记避免"></a>三、非Owner的行为，切记避免</h4><p>什么是非Owner的行为，切记避免：</p><p>1、当整个需求过程中出现问题或存疑点时，别人不说我不说，一直等到最后才发现问题实在不能再拖了才去解决。</p><p>2、当涉及方提出问题时，只说忙于自己的工作没有时间处理；或者觉得这件事不是很重要；或者是看到了，但是不知道怎么回答，所以不回答。</p><p>3、同步结论&#x2F;进度&#x2F;计划时害怕说错，所以干脆不说。我们提出来、说出来的，本身也就希望有人指出问题，所以不要怕说错。（但也要做好一定的了解和思考之后再进行同步）</p><p>这些行为都是缺乏Owner意识、缺少Owner特质的体现。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;Owner需求的模板规范&quot;&gt;&lt;a href=&quot;#Owner需求的模板规范&quot; class=&quot;headerlink&quot; title=&quot;Owner需求的模板规范&quot;&gt;&lt;/a&gt;Owner需求的模板规范&lt;/h1&gt;&lt;h2 id=&quot;Owner的意义-为什么要Owner&quot;&gt;&lt;a hr</summary>
      
    
    
    
    <category term="实习记录" scheme="http://example.com/categories/%E5%AE%9E%E4%B9%A0%E8%AE%B0%E5%BD%95/"/>
    
    
  </entry>
  
  <entry>
    <title>并发编程 |【1】基础知识</title>
    <link href="http://example.com/posts/438d9a07.html"/>
    <id>http://example.com/posts/438d9a07.html</id>
    <published>2024-01-01T16:07:25.823Z</published>
    <updated>2024-03-03T13:19:04.018Z</updated>
    
    <content type="html"><![CDATA[<h1 id="并发编程"><a href="#并发编程" class="headerlink" title="并发编程"></a>并发编程</h1><h2 id="1-基础"><a href="#1-基础" class="headerlink" title="1. 基础"></a>1. 基础</h2><h3 id="1-1-进程"><a href="#1-1-进程" class="headerlink" title="1.1 进程"></a>1.1 进程</h3><ul><li>首先得说说程序，<strong>程序是由指令和数据组成</strong>的。程序运行就意味着 ： <strong>指令要运行、数据要读写</strong><ul><li>（1）前提是必须将指令加载到CPU、数据加载至内存。</li><li>（2）在指令运行过程中，可能还需要使用到磁盘、网络等设备</li><li>此时进程就发挥作用了。进程就是用来加载指令、加载数据(管理内存)、管理IO的。</li></ul></li><li>形象说：当一个程序被运行，从磁盘加载这个程序的代码到内存，这时候就是开启了一个进程。</li><li>因此进程就可以视为程序的一个实例。程序认为是静态的，进程认为是动态的。大部分程序可以同时运行多个实例进程（例如记事本、浏览器），也有的程序只能运行一个实例进程(网易云音乐、360安全卫士)</li></ul><h3 id="1-2-线程"><a href="#1-2-线程" class="headerlink" title="1.2 线程"></a>1.2 线程</h3><ul><li>一个进程之内可以分为一到多个线程</li><li>一个线程就是一个指令流，将指令流中的一条条指令以一定的顺序交给CPU执行</li><li>Java中，线程作为最小的调度单位 (即CPU是执行线程中的指令流的)，进程作为资源分配的最小单位。</li></ul><h3 id="1-3-二者对比"><a href="#1-3-二者对比" class="headerlink" title="1.3 二者对比"></a>1.3 二者对比</h3><ul><li>进程基本上相互独立的，而线程存在于进程内，是进程的一个子集 </li><li>进程拥有的资源，如内存空间等，供其内部的线程共享 </li><li>进程间通信较为复杂 <ul><li>同一台计算机的进程通信称为 IPC（Inter-process communication） </li><li>不同计算机之间的进程通信，需要通过网络，并遵守共同的协议，例如 HTTP</li></ul></li><li>线程通信相对简单，因为它们共享进程内的内存，一个例子是多个线程可以访问同一个共享变量 </li><li>线程更轻量，线程上下文切换成本一般上要比进程上下文切换低</li></ul><h3 id="1-4-并发与并行"><a href="#1-4-并发与并行" class="headerlink" title="1.4 并发与并行"></a>1.4 并发与并行</h3><p><strong>并发</strong>： 时间片轮转，不是同时去做，但是因为时间片很短，近似于同时做</p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo/img/image-20240114150124022.png"/><p><strong>并行</strong>：依靠Cpu的核数，同时去做</p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo/img/image-20240114150021971.png" style="zoom:60%;" /><h3 id="1-5-应用"><a href="#1-5-应用" class="headerlink" title="1.5 应用"></a>1.5 应用</h3><h4 id="应用之异步调用-避免阻塞主线程"><a href="#应用之异步调用-避免阻塞主线程" class="headerlink" title="应用之异步调用(避免阻塞主线程)"></a><strong>应用之异步调用(避免阻塞主线程)</strong></h4><p>以调用方角度来讲，如果 </p><ul><li><p>需要等待结果返回，才能继续运行就是同步 </p></li><li><p>不需要等待结果返回，就能继续运行就是异步</p></li></ul><p><strong>设计</strong> </p><p>多线程可以让方法执行变为异步的（即不要巴巴干等着）比如说读取磁盘文件时，假设读取操作花费了 5 秒钟，</p><p>如果没有线程调度机制，这 5 秒 cpu 什么都做不了，其它代码都得暂停… </p><p><strong>结论</strong> </p><ul><li><p>比如在项目中，视频文件需要转换格式等操作比较费时，这时开一个新线程处理视频转换，<strong>避免阻塞主线程</strong> </p></li><li><p>tomcat 的异步 servlet 也是类似的目的，让用户线程处理耗时较长的操作，避免阻塞 tomcat 的工作线程 </p></li><li><p>ui 程序中，开线程进行其他操作，避免阻塞 ui 线程</p></li></ul><h4 id="应用之提高效率-任务拆分-多核并行执行"><a href="#应用之提高效率-任务拆分-多核并行执行" class="headerlink" title="应用之提高效率(任务拆分 | 多核并行执行)"></a><strong>应用之提高效率(任务拆分 | 多核并行执行)</strong></h4><p>充分利用多核 cpu 的优势，提高运行效率。</p><p>想象下面的场景，执行 3 个计算，最后将计算结果汇总。 </p><p>如果是串行执行，那么总共花费的时间是 10 + 11 + 9 + 1 &#x3D; 31ms </p><p>但如果是四核 cpu，各个核心分别使用线程 1 执行计算 1，线程 2 执行计算 2，线程 3 执行计算 3，那么 3 个 线程是并行的，花费时间只取决于最长的那个线程运行的时间，即 11ms 最后加上汇总时间只会花费 12ms </p><p><strong>注意 需要在多核 cpu 才能提高效率，单核仍然时是轮流执行，甚至因为线程的上下文切换，在单核时多线程反而比单线程慢</strong></p><p><strong>结论</strong> </p><ul><li><p><strong>单核 cpu 下，多线程不能实际提高程序运行效率，只是为了能够在不同的任务之间切换，不同线程轮流使用 cpu ，不至于一个线程总占用 cpu，别的线程没法干活</strong> </p></li><li><p>多核 cpu 可以并行跑多个线程，但能否提高程序运行效率还是要分情况的 </p><ul><li><strong>有些任务，经过精心设计，将任务拆分，并行执行，当然可以提高程序的运行效率</strong>。但不是所有计算任务都能拆分（参考后文的【阿姆达尔定律】） </li><li>也不是所有任务都需要拆分，任务的目的如果不同，谈拆分和效率没啥意义</li></ul></li><li><p>IO 操作不占用 cpu，只是我们一般拷贝文件使用的是【阻塞 IO】，这时相当于线程虽然不用 cpu，但线程需要一直等待 IO 结束，没能充分利用线程。所以才有后面的【非阻塞 IO】和【异步 IO】进行优化，提高线程的利用率。</p></li></ul><p><strong>常用命令</strong></p><ul><li><p><strong>ps -fe | grep java 查看（包括Java关键字）的进程</strong></p></li><li><p><strong>jps  查看Java的进程</strong></p></li><li><p><strong>top -H -p 进程ID  查看某Java进程中所有线程的信息（CPU占用、内存占用）</strong></p></li><li><p><strong>jstack 进程PID   查看某Java进程中某一刻的所有线程的信息（线程的状态）</strong></p></li></ul><p>jconsole工具，本地 Win+R后，输入jconsole，就可以</p><h3 id="1-6-线程运行原理"><a href="#1-6-线程运行原理" class="headerlink" title="1.6 线程运行原理"></a>1.6 线程运行原理</h3><ul><li><p>一个线程会有一个线程栈 (也叫虚拟机栈，会占据一定的内存，属于JVM的内存结构之一)。</p></li><li><p>每个线程的运行就是调用一个个方法，线程内对应的就是一个个栈帧，即一个方法对应一个栈帧。</p></li><li><p>栈帧内有局部变量表、返回地址、锁记录、操作数栈</p></li><li><p>一个线程会有一个程序计数器（程序计数器属于JVM的内存结构之一)，用于记录下一条Jvm指令的地址，cpu从程序计数器中获取指令地址去执行指令。</p></li></ul><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo/img/image-20240227233423711.png"/><ul><li>当method2、method1方法分别执行完毕，就会把栈帧释放掉。</li></ul><h3 id="1-7-线程上下文切换"><a href="#1-7-线程上下文切换" class="headerlink" title="1.7 线程上下文切换"></a>1.7 线程上下文切换</h3><p>线程由运行的状态变成不运行的状态，因为以下一些原因导致cpu不再执行当前线程，转而执行另一个线程的代码。</p><ul><li>线程的cpu时间片用完</li><li>垃圾回收(STW时的用户工作线程)</li><li>有更高优先级的线程需要运行</li><li>线程自己调用了sleep、yield、wait、join、park、synchronized、lock等方法</li></ul><p>当线程上下文切换发生时，需要由操作系统保存当前线程的状态，并恢复另外一个线程的状态。</p><ul><li>状态包括：程序计数器(该线程的代码运行到哪了)、虚拟机栈中每个栈帧的信息内容，如局部变量表、操作数栈、返回地址</li><li>频繁发生上下文切换会影响性能</li></ul><h3 id="1-8-Java线程常见方法"><a href="#1-8-Java线程常见方法" class="headerlink" title="1.8 Java线程常见方法"></a>1.8 Java线程常见方法</h3><h4 id="start-和run"><a href="#start-和run" class="headerlink" title="start()和run()"></a>start()和run()</h4><p>我们调用线程的start()方法，如果有任务对象配合传入Thread，会调用任务对象的run方法，如果没有会调用自己实现的run方法。</p><p>那么为什么不像下文一样直接调用thread.run()，而是要调用thread.start()呢？</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>()&#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="built_in">super</span>.run();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        thread.start();</span><br><span class="line">        <span class="comment">//thread.run();</span></span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>经过实验发现如果直接调用thread.run()，实际上执行run方法的还是main主线程，并非新建线程来执行。</p><p>而调用thread.start()方法会新建一个线程来执行run方法。</p><p>start()对线程状态的影响，多次调用start方法的异常。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> &#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>()&#123;</span><br><span class="line">            <span class="meta">@Override</span></span><br><span class="line">            <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">run</span><span class="params">()</span> &#123;</span><br><span class="line">                <span class="built_in">super</span>.run();</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;;</span><br><span class="line">        System.out.println(thread.getState());  <span class="comment">// NEW</span></span><br><span class="line">        thread.start();</span><br><span class="line">    <span class="comment">//thread.start(); 只能调用一次start方法: java.lang.IllegalThreadStateException</span></span><br><span class="line">        System.out.println(thread.getState());  <span class="comment">// RUNNABLE</span></span><br><span class="line">    &#125;、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、、</span><br><span class="line">    </span><br></pre></td></tr></table></figure><h4 id="sleep-和yield"><a href="#sleep-和yield" class="headerlink" title="sleep()和yield()"></a>sleep()和yield()</h4><p>sleep()</p><ol><li>调用sleep会让当前线程从Running状态进入TimeWaiting状态</li><li>其他线程可以使用interrupt方法打断正在睡眠的线程，这时sleep方法会抛出InterrruptedException，该睡眠线程就会被唤醒。</li><li>睡眠结束后的线程未必会立刻得到执行</li><li>建议使用TimeUnit 的sleep方法代替Thread的sleep来获得更好的可读性</li></ol><p>yield()</p><p>让出、谦让</p><ol><li>线程调用yield方法会让当前线程从Running状态进入Runnable就绪状态，然后调度执行其他线程</li><li>调用了yield方法并不代表当前线程绝对不会执行，是Runnable状态依然有可能被分配到时间片执行，具体的实现依赖于操作系统的任务调度器。</li><li>如果没有其他线程，任务调度器依然会把时间片分配给该线程。</li><li>yield方法和线程设置的优先级高低都仅仅是给任务调度器一个提示，具体是控制不了的。</li></ol><h4 id="sleep方法的应用"><a href="#sleep方法的应用" class="headerlink" title="sleep方法的应用"></a>sleep方法的应用</h4><p>防止while(true) CPU占用100%   90+%  -&gt; 6%</p><ul><li>在没有利用cpu来计算时，防止while(true)空转占满机器的cpu，这时可以使用sleep方法来让出cpu的使用权给机器上的其他程序。</li><li>可以使用wait或条件变量达到类似的效果。不同的是这两种都需要加锁。并且需要相应的唤醒操作，一般适用于要进行同步的场景。</li></ul><h4 id="join-和join-long-n"><a href="#join-和join-long-n" class="headerlink" title="join()和join(long n)"></a>join()和join(long n)</h4><p>等待线程运行结束</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">static</span> <span class="type">int</span> <span class="variable">r</span> <span class="operator">=</span> <span class="number">0</span>;</span><br><span class="line">   <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">       <span class="type">Thread</span> <span class="variable">thread</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;&#123;</span><br><span class="line">           log.debug(<span class="string">&quot;开始&quot;</span>);</span><br><span class="line">           <span class="keyword">try</span> &#123;</span><br><span class="line">               TimeUnit.SECONDS.sleep(<span class="number">1</span>);</span><br><span class="line">           &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">               <span class="keyword">throw</span> <span class="keyword">new</span> <span class="title class_">RuntimeException</span>(e);</span><br><span class="line">           &#125;</span><br><span class="line">           log.debug(<span class="string">&quot;结束&quot;</span>);</span><br><span class="line">           r = <span class="number">10</span>;</span><br><span class="line">       &#125;,<span class="string">&quot;t1&quot;</span>);</span><br><span class="line">       thread.start();</span><br><span class="line">       thread.join();  <span class="comment">// 在主线程的执行路径中加入 thread.join() 表示要等到thread运行结束,自己再运行</span></span><br><span class="line">       log.debug(<span class="string">&quot;结果为：&#123;&#125;&quot;</span>,r);</span><br><span class="line">   &#125;</span><br></pre></td></tr></table></figure><p>如果要等待多个线程的结果，只需要在线程的执行路径上 加上多个线程的.join()方法，就可以等待多个线程执行完毕</p><p><strong>join(long n)</strong> </p><p>例如在main方法中调用t1.join(1000) , 即main线程会等待 t1线程1000ms，1000ms后即使t1线程没有执行结束，main线程也会继续向下执行</p><h4 id="interrupt"><a href="#interrupt" class="headerlink" title="interrupt()"></a>interrupt()</h4><h5 id="打断sleep中、wait中、join中的线程"><a href="#打断sleep中、wait中、join中的线程" class="headerlink" title="打断sleep中、wait中、join中的线程"></a>打断sleep中、wait中、join中的线程</h5><p>interrupt可以打断这三种线程，并且这三种线程会把打断标记置为false。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line"> <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">            log.debug(<span class="string">&quot;开始&quot;</span>);</span><br><span class="line">            <span class="keyword">try</span> &#123;</span><br><span class="line">                log.debug(<span class="string">&quot;sleep&quot;</span>);</span><br><span class="line">                Thread.sleep(<span class="number">5000</span>); <span class="comment">// wait、join</span></span><br><span class="line">            &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                e.printStackTrace();</span><br><span class="line">            &#125;</span><br><span class="line">            log.debug(<span class="string">&quot;结束&quot;</span>);</span><br><span class="line">            </span><br><span class="line">        &#125;, <span class="string">&quot;t1&quot;</span>);</span><br><span class="line">        t1.start();</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        log.debug(<span class="string">&quot;interrupt&quot;</span>);</span><br><span class="line">        t1.interrupt();</span><br><span class="line">        Thread.sleep(<span class="number">50</span>);</span><br><span class="line">        log.debug(<span class="string">&quot;t1打断标记:&#123;&#125;&quot;</span>,t1.isInterrupted());</span><br><span class="line">&#125;</span><br><span class="line">输出结果：</span><br><span class="line"><span class="number">23</span>:<span class="number">58</span>:<span class="number">37</span> [t1] c.Test1 - 开始</span><br><span class="line"><span class="number">23</span>:<span class="number">58</span>:<span class="number">37</span> [t1] c.Test1 - sleep</span><br><span class="line"><span class="number">23</span>:<span class="number">58</span>:<span class="number">38</span> [main] c.Test1 - interrupt</span><br><span class="line"><span class="number">23</span>:<span class="number">58</span>:<span class="number">38</span> [t1] c.Test1 - 结束</span><br><span class="line">java.lang.InterruptedException: sleep interrupted</span><br><span class="line">at java.lang.Thread.sleep(Native Method)</span><br><span class="line">at com.hwg.Test1.lambda$main$<span class="number">0</span>(Test1.java:<span class="number">15</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">750</span>)</span><br><span class="line"><span class="number">23</span>:<span class="number">58</span>:<span class="number">38</span> [main] c.Test1 - t1打断标记:<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>可以看到在t1线程进入睡眠后，main线程尝试使用t1.interrupt()打断正在sleep的线程。</p><p>然后t1线程就被打断唤醒了，继续执行了log.debug(“结束”);</p><p>而且t1线程的打断标记按理说是true，但是像sleep中、wait中、join等待中的线程被interrupt后会将打断标记置为false。</p><h5 id="打断正常运行的线程"><a href="#打断正常运行的线程" class="headerlink" title="打断正常运行的线程"></a>打断正常运行的线程</h5><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">Thread</span> <span class="variable">t1</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">Thread</span>(() -&gt; &#123;</span><br><span class="line">            log.debug(<span class="string">&quot;开始&quot;</span>);</span><br><span class="line">            <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">                <span class="type">boolean</span> <span class="variable">interrupted</span> <span class="operator">=</span> Thread.currentThread().isInterrupted();</span><br><span class="line">                <span class="keyword">if</span>(interrupted)&#123;</span><br><span class="line">                    log.debug(<span class="string">&quot;被打断了,退出循环&quot;</span>);</span><br><span class="line">                    <span class="keyword">break</span>;</span><br><span class="line">                &#125;</span><br><span class="line">            &#125;</span><br><span class="line">            log.debug(<span class="string">&quot;结束&quot;</span>);</span><br><span class="line">        &#125;, <span class="string">&quot;t1&quot;</span>);</span><br><span class="line">        </span><br><span class="line">        t1.start();</span><br><span class="line">        Thread.sleep(<span class="number">1000</span>);</span><br><span class="line">        </span><br><span class="line">        log.debug(<span class="string">&quot;interrupt&quot;</span>);</span><br><span class="line">        t1.interrupt();</span><br><span class="line"></span><br><span class="line">        log.debug(<span class="string">&quot;t1打断标记:&#123;&#125;&quot;</span>,t1.isInterrupted());</span><br><span class="line">        Thread.sleep(<span class="number">50</span>);</span><br><span class="line">        log.debug(<span class="string">&quot;t1打断标记:&#123;&#125;&quot;</span>,t1.isInterrupted());</span><br><span class="line">&#125;</span><br><span class="line">输出结果：</span><br><span class="line"><span class="number">00</span>:08:<span class="number">21</span> [t1] c.Test1 - 开始</span><br><span class="line"><span class="number">00</span>:08:<span class="number">22</span> [main] c.Test1 - interrupt</span><br><span class="line"><span class="number">00</span>:08:<span class="number">22</span> [t1] c.Test1 - 被打断了,退出循环</span><br><span class="line"><span class="number">00</span>:08:<span class="number">22</span> [t1] c.Test1 - 结束</span><br><span class="line"><span class="number">00</span>:08:<span class="number">22</span> [main] c.Test1 - t1打断标记:<span class="literal">true</span></span><br><span class="line"><span class="number">00</span>:08:<span class="number">22</span> [main] c.Test1 - t1打断标记:<span class="literal">false</span></span><br></pre></td></tr></table></figure><p>在这里t1线程是正常运行的线程，main线程调用了t1.interrupt()，但是t1线程并不会停下来。而是继续运行。</p><p>但是这时t1线程的打断标记置为true。而t1线程在自己的工作中可以去判断打断标记，如果打断标记为true，t1线程可以自定义处理一些</p><p>事情再决定是否结束。</p><h5 id="两阶段终止模式"><a href="#两阶段终止模式" class="headerlink" title="两阶段终止模式"></a>两阶段终止模式</h5><p>线程t1如何优雅的停止线程t2 ？ </p><ul><li>线程t1直接调用 t2.stop()，停止线程t2，这样不够优雅，t2线程没有时间来料理后事</li><li>因此才有两阶段终止模式，例如一个服务器的监控线程，一般是while(true)执行，但是也会提供一个停止监控的按钮，可以使用interrupt()来优雅的停止，即给予监控线程一些料理后事的时间。</li></ul><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo/img/image-20240301002010775.png"/><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@Slf4j(topic = &quot;c.Test1&quot;)</span></span><br><span class="line"><span class="keyword">public</span> <span class="keyword">class</span> <span class="title class_">Test1</span> &#123;</span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title function_">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> InterruptedException &#123;</span><br><span class="line">        <span class="type">TwoPhaseTermination</span> <span class="variable">tpt</span> <span class="operator">=</span> <span class="keyword">new</span> <span class="title class_">TwoPhaseTermination</span>();</span><br><span class="line">        tpt.start();</span><br><span class="line">        Thread.sleep(<span class="number">3500</span>);</span><br><span class="line">        tpt.stop();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line"><span class="meta">@Slf4j(topic = &quot;c.TwoPhaseTermination&quot;)</span></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">TwoPhaseTermination</span>&#123;</span><br><span class="line">    <span class="keyword">private</span> Thread monitor;</span><br><span class="line">    </span><br><span class="line">    <span class="comment">// 启动监控线程</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">start</span><span class="params">()</span>&#123;</span><br><span class="line">        monitor = <span class="keyword">new</span> <span class="title class_">Thread</span>(()-&gt;&#123;</span><br><span class="line">           <span class="keyword">while</span>(<span class="literal">true</span>)&#123;</span><br><span class="line">               <span class="type">Thread</span> <span class="variable">current</span> <span class="operator">=</span> Thread.currentThread();</span><br><span class="line">               <span class="keyword">if</span>(current.isInterrupted())&#123;</span><br><span class="line">                   log.debug(<span class="string">&quot;料理后事&quot;</span>);</span><br><span class="line">                   <span class="keyword">break</span>;</span><br><span class="line">               &#125;</span><br><span class="line"></span><br><span class="line">               <span class="keyword">try</span> &#123;</span><br><span class="line">                   Thread.sleep(<span class="number">1000</span>);  <span class="comment">// 情况1被打断-进catch</span></span><br><span class="line">                   log.debug(<span class="string">&quot;执行监控记录&quot;</span>);   <span class="comment">// 情况2被打断-打断标记为true,下次循环会break</span></span><br><span class="line">               &#125; <span class="keyword">catch</span> (InterruptedException e) &#123;</span><br><span class="line">                   e.printStackTrace();</span><br><span class="line">                   <span class="comment">// 重新设置打断标记</span></span><br><span class="line">                   current.interrupt();</span><br><span class="line">               &#125;</span><br><span class="line">           &#125;</span><br><span class="line">        &#125;);</span><br><span class="line">        monitor.start();</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="comment">// 停止监控线程</span></span><br><span class="line">    <span class="keyword">public</span> <span class="keyword">void</span> <span class="title function_">stop</span><span class="params">()</span>&#123;</span><br><span class="line">        monitor.interrupt();</span><br><span class="line">    &#125;</span><br><span class="line">&#125;</span><br><span class="line">输出结果：</span><br><span class="line"><span class="number">00</span>:<span class="number">41</span>:<span class="number">55</span> [Thread-<span class="number">0</span>] c.TwoPhaseTermination - 执行监控记录</span><br><span class="line"><span class="number">00</span>:<span class="number">41</span>:<span class="number">56</span> [Thread-<span class="number">0</span>] c.TwoPhaseTermination - 执行监控记录</span><br><span class="line"><span class="number">00</span>:<span class="number">41</span>:<span class="number">57</span> [Thread-<span class="number">0</span>] c.TwoPhaseTermination - 执行监控记录</span><br><span class="line">java.lang.InterruptedException: sleep interrupted</span><br><span class="line">at java.lang.Thread.sleep(Native Method)</span><br><span class="line">at com.hwg.TwoPhaseTermination.lambda$start$<span class="number">0</span>(Test1.java:<span class="number">35</span>)</span><br><span class="line">at java.lang.Thread.run(Thread.java:<span class="number">750</span>)</span><br><span class="line"><span class="number">00</span>:<span class="number">41</span>:<span class="number">58</span> [Thread-<span class="number">0</span>] c.TwoPhaseTermination - 料理后事</span><br><span class="line"></span><br></pre></td></tr></table></figure><h3 id="1-9-主线程与守护线程"><a href="#1-9-主线程与守护线程" class="headerlink" title="1.9 主线程与守护线程"></a>1.9 主线程与守护线程</h3><p>默认情况下，Java进程需要等待所有的线程都运行结束，才会结束。</p><p>有一种特殊的线程叫做守护线程，只要其他非守护线程运行结束了，即使守护线程的代码没有执行完，也会强制结束。</p><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">t1.setDaemon(<span class="literal">true</span>) </span><br></pre></td></tr></table></figure><h3 id="1-10-线程的状态-线程的生命周期"><a href="#1-10-线程的状态-线程的生命周期" class="headerlink" title="1.10 线程的状态 | 线程的生命周期"></a>1.10 线程的状态 | 线程的生命周期</h3><p>Java中在Thread类里有一个枚举Enum类明确规定了Java线程的六种状态</p><ul><li>创建线程对象–&gt;<strong>新建状态 (NEW)</strong></li><li>调用start方法–&gt;<strong>就绪状态（Runnable）</strong>，<strong>就绪状态</strong>如果<strong>抢</strong>到<strong>CPU的执行权</strong>则变为<strong>运行</strong>（但在Java中依然是Runnable）</li><li>（从运行中）无法获取锁对象–&gt;<strong>阻塞状态（Blocked）</strong></li><li>（从运行中）wait方法–&gt;<strong>等待状态（Waiting）</strong></li><li>（从运行中）sleep方法–&gt;<strong>计时等待状态（Timed_Waiting）</strong></li><li>本身的run方法执行完毕–&gt;<strong>结束状态（Terminated）</strong></li></ul><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo/img/image-20231214001413717.png" style="zoom:60%;" />]]></content>
    
    
      
      
    <summary type="html">&lt;h1 id=&quot;并发编程&quot;&gt;&lt;a href=&quot;#并发编程&quot; class=&quot;headerlink&quot; title=&quot;并发编程&quot;&gt;&lt;/a&gt;并发编程&lt;/h1&gt;&lt;h2 id=&quot;1-基础&quot;&gt;&lt;a href=&quot;#1-基础&quot; class=&quot;headerlink&quot; title=&quot;1. 基础&quot;&gt;&lt;/</summary>
      
    
    
    
    <category term="学习分享" scheme="http://example.com/categories/%E5%AD%A6%E4%B9%A0%E5%88%86%E4%BA%AB/"/>
    
    
  </entry>
  
  <entry>
    <title>《大型网站技术架构》| 读书笔记 | 【1】演化发展</title>
    <link href="http://example.com/posts/4a17b157.html"/>
    <id>http://example.com/posts/4a17b157.html</id>
    <published>2023-12-30T00:00:00.000Z</published>
    <updated>2024-01-30T06:57:06.506Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>书名:   《大型网站技术架构：核心原理与案例分析》</p></blockquote><h3 id="大型网站软件系统的特点"><a href="#大型网站软件系统的特点" class="headerlink" title="大型网站软件系统的特点"></a>大型网站软件系统的特点</h3><ul><li><p><strong>高并发、大流量</strong></p><ul><li>指标：PV、UV、IP、交易额、在线用户数</li></ul></li><li><p><strong>高可用</strong></p><ul><li>系统不间断服务</li></ul></li><li><p><strong>海量数据</strong></p><ul><li>存储、管理海量数据</li></ul></li><li><p><strong>用户分布广泛、网络情况复杂</strong></p><ul><li>系统为全球用户服务，因网络等原因，系统需全球化部署，即海外多地建立机器集群</li></ul></li><li><p><strong>需求快速变更、发布频繁</strong></p></li><li><p><strong>渐进式发展</strong></p></li></ul><p>​<strong>大型网站的技术挑战主要来自于庞大的用户，高并发的访问和海量的数据，任何简单的业务一旦需要处理数以P计的数据和面向数以亿计的用户，问题就会变得很棘手。大型网站架构主要就是解决这类问题。</strong></p><h3 id="网站演化发展"><a href="#网站演化发展" class="headerlink" title="网站演化发展"></a>网站演化发展</h3><h4 id="阶段一-初始"><a href="#阶段一-初始" class="headerlink" title="阶段一  初始"></a>阶段一  初始</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240118195725752.png"></p><ul><li>应用程序、数据库、文件 通通都在一台服务器上</li></ul><h4 id="阶段二-应用服务和数据服务分离"><a href="#阶段二-应用服务和数据服务分离" class="headerlink" title="阶段二 应用服务和数据服务分离"></a>阶段二 应用服务和数据服务分离</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240118195708412.png"></p><ul><li><strong>问题：</strong> 用户多导致性能变差，数据多导致存储空间不足</li><li>应用数据和数据服务分离 &#x3D;&gt; 应用服务器、文件服务器、数据库服务器</li><li>三台服务器对硬件资源的要求各不相同<ul><li>应用服务器——应对大量的业务逻辑——更快更强的CPU</li><li>数据库服务器——快速的磁盘检索和数据缓存——更快的硬盘和更大的内存</li><li>文件服务器——存储大量用户的文件——更大的硬盘</li><li>应用和数据分离后，不同特性的服务器各司其职，提高了网站的并发能力和数据存储能力</li></ul></li></ul><h4 id="阶段三-使用缓存改善性能"><a href="#阶段三-使用缓存改善性能" class="headerlink" title="阶段三 使用缓存改善性能"></a>阶段三 使用缓存改善性能</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240118200309557.png"></p><ul><li><strong>问题：</strong>用户多，数据库压力太大，导致访问延迟，进而影响整个网站的性能，换句话说：<strong>数据库成为了系统瓶颈</strong></li><li>二八定律：80%的业务访问集中在20%的数据上</li><li>因此给这20%的数据缓存在内存中，理论上就可以减少数据库的访问压力，提高整个网站的数据访问速度。<ul><li>网站使用的缓存可以分为两种<ul><li>缓存在应用服务器上的本地缓存<ul><li>1、受应用服务器的内存限制</li><li>2、出现和应用程序争用内存的情况</li></ul></li><li>缓存在专门的分布式缓存服务器上的远程缓存——理论上可以做到不受内存容量限制<ul><li>1、集群的方式  （例如Redis的集群方式、Codis等）</li><li>2、大内存的服务器</li></ul></li></ul></li></ul></li></ul><h4 id="阶段四-使用应用服务器集群改善网站的并发处理能力"><a href="#阶段四-使用应用服务器集群改善网站的并发处理能力" class="headerlink" title="阶段四 使用应用服务器集群改善网站的并发处理能力"></a>阶段四 使用应用服务器集群改善网站的并发处理能力</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240119101020800.png"></p><ul><li><strong>问题</strong>：使用缓存后，数据访问压力得到有效缓解，但是单一应用服务区能够处理的请求连接有限，在网站高峰期，应用服务器成为整个网站的瓶颈。</li><li>通过负载均衡调度服务器，可将来自用户浏览器的访问请求分发到应用服务器集群中的任何一台服务器上，如果有更多的用户，就在集群中加入更多的应用服务器，使应用服务器的负载压力不再成为整个网站的瓶颈。</li></ul><h4 id="阶段五-数据库读写分离"><a href="#阶段五-数据库读写分离" class="headerlink" title="阶段五 数据库读写分离"></a>阶段五 数据库读写分离</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240119101646523.png"></p><ul><li>应用服务器在写数据的时候，访问主数据库，主数据库通过主从复制机制，将数据更新同步到从数据库，这样当应用服务器读数据时，就可以通过从数据库获得数据。</li></ul><h4 id="阶段六-使用CDN和反向代理加速网站响应"><a href="#阶段六-使用CDN和反向代理加速网站响应" class="headerlink" title="阶段六 使用CDN和反向代理加速网站响应"></a>阶段六 使用CDN和反向代理加速网站响应</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240119102905980.png"></p><ul><li><strong>问题</strong>：全球网络情况复杂，网站访问延迟，用户流失</li><li>CDN (内容分发网络) 的作用<ul><li>通过在多个地理位置建立一个入网点或一组CDN边缘服务器来工作<ul><li>缓存</li><li>动态加速(优化CDN服务器与应用服务器的连接)</li><li>边缘逻辑计算</li></ul></li></ul></li><li>反向代理的作用<ul><li>负载均衡，根据访问流量和服务器负载情况，将请求分发到不同的应用服务器</li><li>缓存</li><li>保护服务器，隐藏服务器真实 IP</li></ul></li><li>目的：都是为了尽早返回数据(缓存)给用户，同时也减轻了后端服务器的负载压力</li></ul><h4 id="阶段七-使用分布式文件系统和分布式数据库系统"><a href="#阶段七-使用分布式文件系统和分布式数据库系统" class="headerlink" title="阶段七 使用分布式文件系统和分布式数据库系统"></a>阶段七 使用分布式文件系统和分布式数据库系统</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240119104722478.png"></p><ul><li><strong>问题：</strong>一台数据库&#x2F;文件服务器是满足不了持续增长的业务需求的。</li><li>分布式数据库是网站数据库拆分的最后手段，只有在单表数据规模非常庞大的时候才使用。</li><li>网站更常用的数据库拆分手段是业务分库，即将不同业务的数据库部署在不同的物理服务器上。</li></ul><h4 id="阶段八-使用NoSQL和搜索引擎"><a href="#阶段八-使用NoSQL和搜索引擎" class="headerlink" title="阶段八 使用NoSQL和搜索引擎"></a>阶段八 使用NoSQL和搜索引擎</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240119105539838.png"></p><ul><li><strong>问题：</strong>网站的业务越来越复杂，对数据存储和检索的需求也越来越复杂</li><li>网站需要采用一些非关系型数据库技术(Redis、MongoDB)、非数据库查询技术如搜索引擎（ES）</li><li>应用服务器则通过一个统一数据访问模块访问各种数据，减轻应用程序管理诸多数据源的麻烦</li></ul><h4 id="阶段九-业务拆分-分布式服务"><a href="#阶段九-业务拆分-分布式服务" class="headerlink" title="阶段九 业务拆分-分布式服务"></a>阶段九 业务拆分-分布式服务</h4><p><img src="https://cdn.jsdelivr.net/gh/xiao-hwg/imgRepo//img/image-20240119110456687.png"></p><ul><li>问题：日益复杂的业务场景</li><li>使用分而治之的手段将整个网站业务分成不同的产品线<ul><li>例如大型购物交易网站会将 首页、商铺、订单、买家、卖家等拆分为不同的产品线，分归不同的业务团队负责</li></ul></li><li>技术上，会根据不同的产品线，将网站拆分为多个应用，每个应用独立部署维护<ul><li>应用之间可以通过访问同一个数据存储系统构成一个关联的完整的系统。</li></ul></li></ul><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>大型网站的架构演化到这里，基本上大多数的技术问题都得以解决</p><ul><li>另外还有一些跨数据中心的实时数据同步问题  可以通过组合改进现有技术架构或引入新技术组件解决</li><li>如何把自己已经解决的问题的方案应用到别的业务上去 — 建设云计算平台，将计算作为一种基础资源出售，企业按需付费，另外存储、网络都可以按需购买。</li><li><strong>理解已成熟的网站架构技术方案的来龙去脉和历史渊源，在技术选型和架构决策才能有的放矢，直击要害。</strong></li></ul><h5 id="价值观"><a href="#价值观" class="headerlink" title="价值观"></a>价值观</h5><ul><li>没有哪个网站从诞生就是大型网站 (庞大用户、海量数据、高并发访问)，大型网站都是从小型网站发展而来的。</li><li>网站的价值在于它能为用户提供什么价值，而不是网站怎么做的，用了什么高级技术，否则就是舍本逐末。</li><li>驱动大型网站技术发展的主要力量是网站的业务发展，业务成就了技术，不要为了技术而技术。</li><li>当出现技术架构解决不了的问题时，可以看看是否是业务架构有问题。</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;blockquote&gt;
&lt;p&gt;书名:   《大型网站技术架构：核心原理与案例分析》&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3 id=&quot;大型网站软件系统的特点&quot;&gt;&lt;a href=&quot;#大型网站软件系统的特点&quot; class=&quot;headerlink&quot; title=&quot;大型网站软件系统的</summary>
      
    
    
    
    <category term="读书笔记" scheme="http://example.com/categories/%E8%AF%BB%E4%B9%A6%E7%AC%94%E8%AE%B0/"/>
    
    
  </entry>
  
</feed>
